which data man, you know, yeah, i want everything and then i will decide what i want. so this was that face-to-face meeting, okay. but it does not, there is not, so there are things in the abstract record that we definitely do not want in the gdf format, like the frame rate eye movement. you know, we are expecting the gdf format to be sort of a parsed version of events. and you know, there is just too much raw frame rate stuff coming out of this. you would not want it in this kind of format for a translation data thing. yeah, we always get that through. we are not throwing anything away. we are not throwing anything away. we just decide to re-jig this at some finer method. we will still have the original end a method of filtering. but the way to think of this is, this is the data that we want to be able to analyze against the other tracks of data. so the data that we want to compare with the language or with whatever. so as long as the format in which we pick it up is a format which could be generalized to a finer take, because the worst thing that can ever happen to you is you discover that you have done huge amounts of analysis and you actually had the data. you threw it away because you treated it so grossly. yeah, okay. so in essence, whatever we should be able to backtrack and say, okay, instead of every second, every tenth of second or some such thing. well, we are not doing frame rate at any frame for, well, maybe we are. i do not know. i had thought we were, yeah, the eye tracker does. right. well, the kinds of events that we had before talked about putting into the record, but then, yusin, alana, and nxt, is not based on saying every ex seconds something. give me what is happening every ex seconds. it is more like, give me the fixations and what needs to know the duration of these things, right? yeah, duration would be able to say. is the difference between saying that something is in a particular state every frame, whatever the frame rate is, ten seconds a minute. that is one kind of way of looking at data. and a parsed version of the data, which is not at any particular length. it relies on this really close frame rate. well, so there is the real time. there is only events. what i am trying to figure out is whether we have thrown time away. no, no. the time is still in there, but what you want is to figure out what are the, what are the concepts behind that data that you want represented. so rather than saying, the eye was at this particular place here and then a tenth of a second later here and then a tenth of a second later here, you say there was a fixation from this time to that time and that was blank from this time to that time. okay, so one of the formats in which i track your data is analyzed is percentage of time spent on some target as opposed to some competitor over the first second after some event. okay, so you actually have to be have to show at some time slice rate where the eye was on the same target as the other guy, a similar target, what we would both been dealing with. so we have to, we have all the parts, the interesting parts of the screen identified and be able to show distribution of gaze over time. all right, now we could be really unlucky and somebody would expect us to do that at the real frame rate. but i think that is really unlucky, but my point is that we mustn't throw away or lose the capacity of being able to deliver that kind of data. so the two issues here, we are not throwing anything away, but the question is what tool would you use to get that information out of the data? would you be so the more you can plan, typically the eye will move, right? so over any one second, the eye is actually fixing on a bunch of different things. and so when you say the eye was on this from here to here, what is going to happen is that if you use the real frame rate, it is going to jiggle all over the place. it is going to be on this landmark. it is on this object, that object, this fixed thing, that fixed thing. okay, you are going to get lots and lots of stuff and it is percentage distribution that you are going to want. it is not, i went here, you know, it is like person walking, i went here, i stayed here. it is more like fly hovering. so you need to know the percentage of time it was on during that fixation. because if you take them as separate events, you get thousands of separate events. yeah, but the sort of start and end times will give you that, say, that, as a, and then you just measure against, you know, against big friends. yeah, the culative total timer. okay, so the percentage is, it is not something you are using for measurement. it is a cut off for whether or not it counts as a fixation. well, that is the, that is the problem. there are two ways of doing it. one is that there is always a cut off, right? but the other is that there will be a time span, a kind of reaction to some event span. yes, i will lag in some of it. i suppose there is the secadic movement itself. and so i mean, there are really two ways of looking at this. one would like to know, for example, the percentage of time overall in which two people are looking at the same thing. okay. and one would like to know sequences of, they did not look at the same thing and then they broke it. or they did look at the same thing and then they did or did not break, you know, one, one could imagine those two categories. that is, that is a kind of testing of our hypotheses. but there is a certain amount of, , dues you pay to the way they do things in the literature to get your papers published. and one of the things they will want to know is an event series after some critical event. right. one percentage of time is given to looking where the other guy is looking. and one percentage of time over some, you know, reasonable time span of a couple of seconds. right. so they will be, they will want to see essentially the gaze settling on particular incidents, on particular places. so we have to be able to deliver those two things and they are rather different demands. right. the, the should still all come at the little sketch. i asked this for last week about nxt and whether it would have that sort of tiered effect. so you could see the overlap of where one person is looking compared to the other in their mouse movements and things. yeah. that should. because all you want to know is whether they were looking at the same object in the period after. but because it is also based on the, the time course of the procedure, you will be able to basically get a scan path at the pattern of events from that. okay. can we try it to make sure that that, , that this is satisfying elements. i did have it somewhere. i did not have it. well, there is a whiteboard, right? we love this thing. see if the pens work. so, , this is, , a is eyes, right? and b is eyes. and i think what you are saying, you should probably draw this. right. is that they, you know, if, , from this time to this time, they are looking at triangle one. what you are saying is that you want to know in the critical, you want to know after they are, they are looking at triangle one. what is happening in this period with the sky, right? or how? let us, let us imagine a typical construction event. okay. there is some part. there are, there are separate movable parts on the screen ready for use. right. there may be or not a construction already begun. and somebody makes the first move. there is some kind of counication, either gestural, imaginary, or verbal that plans how we are going to do it. before that happens, the person who speaks is going to do some kind of visual scanning. while they are speaking or counicating in some way, the other person may or may not be looking where they are looking. okay. they may be overlapping gaze at particular objects, which are of interest. let us call it the construct, existing construct, which could be zero. right. or the, the addend, the thing which is next going to be added, next piece. okay. now in neither case, when you draw this, he is looking at triangle one, which you are actually drawing, you know, for the period of time in which he is steadily looking at triangle one is going to be very, very short. right. because staring fixively without interruption, blink or, or saccade is, is in extremely short event. at that point, the lped, all the individual fixations, as long as it does not move off that triangle together is a two-total sense gaze. so it is in a region. it is in a region. that is a target, maybe. okay. but even so, you are likely to get bouncing in and out of the region. right. so even so, you want to look at if we are interested in how long before the construction move takes place, how much of the time they spend looking at the same thing. let us call that our measure of alignment. so they are going to be, yeah, that is right, a is going to be on triangle one and various other places. that is right. and b. okay. and we are going to look at the percentage of that time where they are both in the same region. right. so what i want to make sure is that we do not simplify, do you know what i mean? temporally simplify too much. so that, yeah, i mean, as long as we are, because then you lose percentages. yeah. there should not be anything to see. right. and so b has some periods of looking at one and all, which will also be intermittent because. yeah. so, you know, he might get triangle one there and now maybe this one is going to overlap quite a bit. yeah. so what you want to do is be able to define bigger periods, which is the period when they are sort of interested in triangle one overall. right. this is sort of when they should be. when they should be. if we have an event at that, yeah, the second, like, name for the second before it. and then we can just take that chunk out and do something with it. yeah. but that is that should. okay. that is not something that you can do in the nxt query language, but you cannot do that in any, you know, this is such a special purpose. but it is easy enough given the data format for any of these things to do that. so you could do it on, because it is just a matter of the hard part is deciding how close together these have to be before you decide that this is an event that you want to pull out. because, you know, algorithmically, you are already putting together. i mean, this is essentially already, you know, these fixations with stuff in between. and, you know, we have got an algorithm for deciding one that is a look, i guess. you already have that or no? well, it is just based on a stable fixation for sure, or something crossing into that region. oh, yeah, yeah. so it is all fixations. these are all fixations and cots, but within the, yeah. so that is easy enough. so the hard thing is they could be moving their ir betrayally here, right? and, you know, maybe even having fixations on other things. yes, yes, yes, because for example, for part of that time, both b and a are probably looking at the construct. okay, if your intention is to move the red triangle to sit on top of the thing already constructed, you would tend to look that forward. yep. so this is able to, yeah, but what you need to do is we can already build into this gdf format, these regions, if you can give a definition of what you think that is. but i think the right way to do this is to be able to inspect the data in some tool and play around with the definitions, because you will not get it right the first time. yeah, sure. so the question would be under what tool should we be looking at these events? and it allows a reasonable choice for that, right? what you need is something, well, no, because you need to, you need to be able to see the effects of this. so i guess this is a case of craig writing some scripts. so robin having some ideas about what the relationship is and saying, you know, add this data automatically. i mean, it is not that hard, right? it is just there will be a bunch of these. you will have some rules about how, maybe how long you spend on other objects and whether the other object is the existing construction or not. right? right. so essentially this, this, a e is divided into tr1 and c and other stuff. okay, where c is the construct of the existing thing. right. so if they, if they, they had a fixation on c, you would not be worried. but if they had a fixation on c, we take a separate, we would look at the percentage time. i mean, i have no idea because i do not know how people look when they are building things together. okay, so there is a, there is the addend and the, and the, the existing construct. and i do not know whether they are going to spend more time looking at one or the other. but if they are, whatever it is that one is looking at it, the other is looking the same place. they are in good shape. but you know, they are going to look at the clock. yeah, sure. i am not going to look at it. and that is what the other stuff is. we are not going to look at it. that is what the diagonal stripes are for. that is true. but we can, one of the things we will be doing is categorizing people. i take it or interactions by the amount of time people spend looking at the clock. we expect that we put people under time pressure. they will look at the clock a lot more. but that is like a separate analysis, right? sure, it is a separate analysis, but you do not want to throw it away. right? so, so every step, if all of these things are actually categorized by the eye tracker as to where the eye is, right? you should be able to pull out any interesting category and say, all right, for this phase, it is tr1 or c. for this phase, it is, it is q1 or c. but what we find, what we can get out of the data easily at the moment is at this kind of level, right? and then it is a case of defining algorithmically all these other transformations that you want. so this is one we had not thought of adding before, but we should, right? which is, well, how would you decide whether something was the current addend that you have to actually transcribe the thing or watch the film for the moment? so that is a han decision. yeah, absolutely. yeah. yeah, so, so i mean, once you have got that some information, you do, well, you have got the gdf format, you then filter it to say, right, between time x and time y, they are, they are constructing it, they are adding triangle 1 to the construct. and then you just say, in that time period, what essentially they are looking at triangle 1, what essentially they are looking at the construct? so that is, that is that is that is that is that is that is that is the addend and the construct should be, you know, kind of, yeah, they, they change their true identity, but they are, they are categories of stuff. now, i, yeah, kind of assption was that, that this was jp land, that that is what he was, what he was really interested in was the kind of coding which would define the building sequence. okay. so, and the, and maybe he wants to think about that more and say, well, they were several candidates for the addend. all right. and, and it was the negotiation of which candidate was going to be the right candidate. it is actually the interesting stuff. so i should talk to him about this. he is, he is actually, but we emailed me with a list of things he wants to discuss at length. so, but we, we, jp to be defining that maybe. well, this is my question for him. is he going to define this kind of building sequence in a way that we can get out or see? so i mean, you know, they have been working on construction there for a while. so maybe that they have a coding system that is ready to go and we should just apply it. yeah. okay. okay. they do a lot of subassembly, the tasks they have been doing. so they may well have a, i could believe them, you know, taking an interest in that. well, that is fine. i mean, the general division was language here and other stuff there, right? right. so, i would just do that. right. what? well, we have, i will just add it back. i mean, actions might mostly be theirs, right? but since we have the, the eye tracker, we are going to have to answer their questions. oh, yeah. eye tracker here. yeah. i mean, we know that. but so they will, they will tell us something about that. but presably what you would, piously hope, is happens here is what happened with transactions, right? that the verbal analysis and the, and the visual analysis give you the same breaking points, the same chunking points. well, yeah. but i mean, with transaction coding on some like this, you would use, you would not consider it verbal analysis exactly. it would be verbal plus action. because i mean, but it is a task breakdown. it is just a set. it is a task breakdown. but for the verbal version, there are ways of announcing that now we are doing a new one, right? yeah, but you would not have, you would not do two coatings for task level one. no, you would not have to transaction code in that. one of the things, one of the things you would like to establish, you know, as an, as an outcome of this is that you could analyze either end and you would get the same chunking of the material. i do not think that is real estate because i think what you would do is, you know, you would get the same chunk. what you would actually do is use the full record of what you have and do a segmentation. i think it would be hard to understand what was going on if you use like just the language without which in the video to decide whether we are breaking down the task. it is a hypothesis. oh, you do not want it to be coding based on that though. and then that seems a strange way to go about things. well, the language events are multimodal, right? you know, they are doing all these things together. they are doing these things together, but one of the things that you, one could imagine doing is, you know, having the transcription there and just play it back to a bunch of captive undergraduates. why do you care whether they stop stuff? they can do it just based on the language because essentially you are looking at cycling sequences and discourse. and if the discourse tells you what is going on, that is information. i mean, one of the questions is how the information is going to be shared across these media. and if you can get it all out of the speech, you know, if all of the chunking is available when there is speech, okay? then it is carrying a lot of the burden. well, it seems to me that is more important than the other things one could get out of this data. but, you know, but this is, but it is possible. we have not looked at data like this with this, with our old fashioned analyses, you know, and it would be really nice to know that much information, that chunking of the task information is being carried by the language because jp is question, the overriding question, is so what is language for? you know, people are busy interacting all the time and all of our colleagues do not even bother to control for whether people are talking to one another when they are doing these joint tasks because it seems to them to be irrelevant because language is irrelevant. it would actually be nice to demonstrate that in a place where we are controlling whether you have language or not, you can get the entire chunking of the task kind of the language. yeah, well, i can see maybe wanting to know whether you can do the chunking just based on the actions without the language in cases where they use both. it is more, i cannot quite see why it is important to know that they can do it just based on the language when you know that they have both. because you know it is a self-contained system as opposed to a system which cannot be interpreted without the other system. -h. well, i think that was just about to fail. that was just about to fail. almost all studies on language claim that language is a self-contained system which will give you everything you need to know. really? that is the claim. okay. anyway, i did not say it was true. that is the claim and so it is worth testing. so back to this main problem which is, you know, the record that we are getting in the first instance is about these, you know, they are looking at some region of the screen to find dynamically. and then we need some way of knowing what the, you can see adding these other analyses about, you know, they are jointly focused on this region and trying to figure out what is percentage of time they are looking at it. as adding new tiers of information to either the alon track or nxt, they are both sort of track based in this way. but the hard part is knowing how you want to do that. and i think in the first instance what we are trying to get into the gdf one that is just this and then we have got no option but to figure out a way for like to look at this, just explore this data, suggest ways about doing it and be able to play them back and see when we think we have got these things right. i do not think we even know what the set of these things are that we want much less how to get out of it. and we will then establishing the full set, you know, take us much of the project. so yeah, that is right. so this is not, you know, this is something we are aiming for but this is not something that affects what craig is programs for the initial gdf translation. my only concern, as i said when i barged in was just to make sure that we did not lose the things that we might need to pick up later. so let us just return to this question of frame rate because this is the thing we were not planning to transfer into this format. so again, you know, a frame rate kind of coding is, can again be seen as a track but it says everything is coding like this, right? where you say it is state a, state b, state c. but since the definitions of look a thing we are looking at are the ones which get rid of the lower level like chiggling around in the area of a particular object, right? so if we are moving the green triangle, we have defined a region which is dynamically the green triangle wherever it is, we will jiggle around in there but it does not matter where we are in there. that is right. but these are level of analysis. you are happy that it is not going to have frame rate like this. it is going to have an interpretation like this. well, that interpretation is definable to frame rate by the only way we are going to use frame rate. what does that mean? sorry. well, i mean, because i can say for how many frames this fixation went is officially defined. so as long as it is not an untimed event. okay. yeah, all events have a start time under the entire time. so it is fine. i can say it is a long one or it is a short one or it is 20 milliseconds more than that one. it seems to me that alan is concerns might mean we need to add more information to these tags because this thing in itself is a bunch of fixations with the cards. so things like fixation, the nber of fixations. fixations and the percentage of time those fixations cover you might want. yeah, there is some some measure of the so we could work out the nber of fixations that made and the average fixation duration as well. because having long steady fixations can be informative. and so can i have a fixation as percentage of it? this is not a leading question. this is a question question. why would that be informative particularly? if they are holding there, if there is less dancing around the cognitive focus tends to be in one sort of part. so there is a difference between if they, even though they are still looking at the same part, if they are looking around it and rather than just holding their gaze steady or on it. so you think that for example if they are looking at one or another apex of triangle, it would just make a difference. yeah. and we are exploring the thing. as opposed to they were simply, all right, there is there it is. so that really means that we are not throwing away absolute fixations. no, i would not. they have to throw away. screen location with absolute fixations. but the actual look. no, no, this is still smary data. we are talking about just adding attributes to these things that say the nber of fixations that counted as that looking at triangle one, right? so it is possible. exactly. so i understood you to mean exploring the figure because you know, your fixation is point and the figures are bigger than points. so you could be exploring the figure or you could be just somewhere in the region defined as the figure, but not on it. well, yes, but that probably is not going to be easy to get. okay. because they have to break up the parts. so you just want to know the variability of the fixation. i would not that differ from person to person? yes, it can do, but it is also looking at it within their own behavior. okay. so it is the nber of different spots within that region where the i as fix. i would say just the nber of fixations. the nber of different. so the spots will be different anyway. so it is too high. you are not going to have the same pixel. so we have the option that we can put in an a fixation thing here, right? well, if you want the smaller coding in here, so that it is not just parsed into this idea of which object, but you also have the raw fixation data. we can put that in as another track. if you think that that is something that you might want to look at in one of these tools that shows you the tracks against each other. well, all i understood you to ask for was the duration. yeah, that is all he asked for. yeah. well, i think we have got everything. then as well as it is you can come back. you can always, yes, it is you are not throwing anything away then. yeah. and in nxt, there is no cost right because the you just do not choose to load those. right. all we are doing is dping it as output that you can load if you choose to. you know, so if the things that you just know are crazy and you are not going to want, then we do not do it. but otherwise we go ahead and dp them because it is easy to dp up the fixations. yes. so it is a nber of different. okay. so it is the nber of fixations. well, actually, do you have the average duration? do you want the other ones? did you want the other ones? but duration times will somehow, whether it is the average one or. duration of each fixation in the region. not eat? well, if it is each, you have to break it down into another tier, right? you cannot, you can say there were three fixations and they averaged a certain time, but you do not want to. the average should be all right to work. well, what about the overall s of the durations? is that, i mean, which way do you want it? it is not the nber of fixations in the average time. yeah, but that is the way you want it, that way around. yeah. so that is a measure of jiggle in the region, roughly. and did you want the percentage of time fixated, as opposed to, which is sort of another view of this nber? you can have as many of these as. you should be able to derive that presably from. well, it is not, the extra cost of having these as attributes is not high. so, you know, it saves you having to do, right scripts to do arithmetic on that later. if you know that these are nbers that are going to be useful to you. what is our error of measurement on location on the screen? so to what degree do we actually know whether the two little eyes, little circles are exactly in the same place? or just somewhere in the same region? it can vary a bit depending on the calibration. but we are building in a sort of error margin. we would be some pixels around, but there will also be a minim one, because i am trying to think it is probably the small, the actual mouse icon is so small, it will need a slightly larger, just because it is, yeah, okay. so a larger area of error margin around it. okay, so my question is going to be, the mouse is a dynamic object, right? the eye track is a dynamic object, or is it only the piece that the other person is eye track is on? that is an object in this definition. no, the other person is gaze position. is an object. okay, with some, with plus or minus something or other, yeah, around it, some circular area. and so you can be on the object, but not on the other person is gaze. so there can be a triangle, which has, so if there is gaze in the center, and your gaze actually happens to be here. yes. you are in the triangle region. but not looking at their individual. but they probably will avoid looking directly, if they are looking directly at it, it is obscuring the part. but it is directly at it when, when these two, in this situation, when these two overlap, right? like this. yeah. yeah, something about that is going to cut that, because the program we have got there is just in it, they are only looking at one thing at a time. so whether it is triangle or whatever else. so what you are just saying is, they can be looking at the triangle and maybe a nice point and maybe an eye at the same time. well, it would come up, it would say yes. right? i mean, because they would be in the same place. so if you, you are going to have dynamic regions which overlap one another by definition, if the mouse is on the construct. the main thing is the trees and then the trees. yeah. well, those are different tracks of information. so what you want is one track of information about which object it is on. what about whether or not it is something other guys gaze and what about whether it is on one of the mouse. we treat those as other objects, but the difference between them and the parts of the thing to be constructed. is that they are allowed to overlap with other things, nothing breaks. okay. yeah, but in the analysis, you should treat those as completely separate tracks of information. because they can be looking at, they could look simultaneously at somebody is mouse, somebody is gaze and some object. right? yes, as opposed to simply looking at somebody is gaze when the mouse is not also there. right. and you want to know those things. so these are independent. right. so they are independent dynamic objects. so what we want is whether they are looking at the other person is gaze, right, and say they are in this period. well, i mean, it is okay. so a definition of we are all looking at and touching the same thing. so imagine that we have just added a piece to the construct. all right? so now that is the construct. and both mouse symbols are on it. right? and both gazes are on it. yep. right? so at that point, you should have a lineup of a is on the construct, a is on the mouse, a is on a is on a is mouse, a is on b is mouse, a is on b is on b is gaze. and b likewise. yeah. okay. so there is a lot of tracks here, right? because we just did a this fixation track. and then there is a is mouse, not their eyes, is on an object, right? and the mouse might be on it. yeah, but the mouse is also triangle one dynamic object. but it does not matter. that is fine. okay. the mouse, which thing, where is the mouse? you know, it is on this object. and a is eye is on, well, a is mouse, i guess, right? a is eye might be looking at a is mouse here. a is eye might be looking at b is mouse here. right? i mean, these are all the different ways of taking cross products and the things that could be collocated. so you just treat them as independent. and then you look for combinations of them. yeah. i am guessing from what you are saying, you want all these tracks. i think we need to. yeah, we will just find a measure of the line. and looking where the other guy is directing attention. and there are two measures of where the other guy is directing attention that you get from the visual track. one is where the mouse is. yeah. the other is where the gase is. so you kind of got the idea here. yeah, yeah. yeah. so, yeah. so it is just a matter of adding the two mice pointers and the two gase as extra objects. so, yeah, some of the songs i have got an id in there. we can just say, right, at this, between these times, they are looking at that object. or the look of the mouse, the look of whatever. but the important thing is you do not treat the entire set as mutually exclusive and exhaustive. it is just so that the object is like a separate level of analysis. it is what if it were going to be objects, then whether they are looking at the gase. but it is also going to be the case that whatever region you define as the region of the dynamic object of the red triangle may get to the point where it overlaps the region of the dynamic object of the green square. okay. what do we do about that? does that happen? yeah. because if you have them close together, there is always some fuzz factor around there. and so if they are left lying close together or in fact in the model, in the not in the model in the supplies set, they are actually neatly packed into a little space. okay. so what you are saying is like a new problem for us, which is. so if your objects close together, your i gase can actually be looking at the left edge one and the right edge of the other. they are looking at two objects at once. yeah. so you are saying. sweet. sweet. okay. can you write on my pen pad? just to say, yeah, pens. whiteboard pens. so you are saying, you know, they could be looking at square one at this point. because they. because the two are so close together that their regions overlap. okay. that is a problem for the data models and either the things that we are using. but unless we just define it as. there is only that they are exclusive and whichever area has a greases overlap is what they are actually looking at. what do you mean by greatest overlap with one? if you have got your sort of eye position and it is. it is unlikely to be exactly 50% or one object 50% in the other. draw it. my special reasoning is no good. i think i think it is seeing information. i am the one that uses the whiteboard because i actually put the microphone. yeah. what i am i am thinking is if you have got. see one object there and. you know, so this is the better pen. okay. part one and part two. and you have got their sort of they are looking. there. -h. then that overlap means they are looking at two pieces simultaneously. yeah. but you had a way of choosing which one right? yeah. and that is the idea is more of it. it may be a bad idea. you just throw it in a day. yeah. that is a decision. well, the thing is that i am saying is if they are looking at most of what their overlap is here, then we stick with that one. so you just mean which is it closer to the. is the circle and what is the circle they are looking at pixel or something right? no, that because the gaze position will be a sort of fuzzy area. it would not just be a pixel. it will be an actual. like a circle and the area. the gaze will wobble. so that is that is going to be. it is. so that is very a size. it is a sort of lp. target. so there will be a bit of a. some sort of overlap. two objects. or indeed they might be looking from one to another. yeah, they are. yeah. it is just like, you want to choose or thinking so you do not want to decide it is only one. the only thing is the only gds for it is working at the moment. it is actually got separate track for each part. okay, well, that is fine. that i was going to say that is the obviously. oh, but what? yeah, that is going to be analytically because it is going to. is he has to know how many parts of it? well, it depends on what you build and there is different parts of the different parts. whether you do in the tangram way, they are playing or whatever. six to a dozen. okay. the thing is if we have got to see the track. i know ways of getting around the track. we can easily analyze it down. play it wrong. i mean, i think it is very likely that. i mean, if the other oscillating thought then that is presably going to change the week. so you are actually going to see them flipping between. well, not as the regions overlap. if they are really close to the region, it is going to get fixed. yeah. and if you define the regions so neatly that there is, you know, that we are losing gaze because of jiggle outside this closely defined region when it is in the middle of space, then. i mean, i actually like the solution. however, ugly it looks in terms of a data format of having a track for every. yeah, well, the data format i am worried about. it is the way you do the analysis because you do not want to have to say, you know, did they jointly look at triangle one? okay, did they jointly look at square one? okay, did they jointly look at, you know, you need some way of going over the whole thing, but we can find ways around that. i think for now we do it this way and then we think about what we need out of it in the end. it is just, you know, in a lawn that has the side effect that if you go for the naturalist way of up translating to a lawn, there will be a zillion tracks. and it will probably ruin their viewer because you will get very sparse data on each track. it will be like the old referring expression generals visualization in the map task. you know, when they talk about one object, one landmark and then another one that was brilliant. well, it is big, right? yeah, it is big and you do have to scroll through it to see what is going on, but because you very clear picture what is going on. well, we will see if a lawn likes it or not. yeah, well, okay, so we better do a test one and we better also like have in the representational list of parts, like even in the nxt of translational list of parts. yeah, it affects the way we do the nxt. yeah, but there is only list parts in the gdf. so, yeah, that is not a problem. there is a base basically, well, there is three places where you have got the id there. so you have got an id for a part. you can id for a location on the screen, such as the target config, the clock, whatever else. and then we can easily add ids for the two most points and the two gazes. and from that, and basically all the tracks are doing is saying, at this, between this time, there is a look at this object. yeah, this id. so, let us say it is effectively a track for each id. okay, so what about the point where a part becomes the construct? you still identify it as part. yeah, but what should lose that? well, what happens there is that the two, the existing parts basically cease to exist. right. and a new part with a new id starts existing at the point where they are joining. so every time a part is added to the construct, it becomes a new part. so the construct actually has, say, it has six things that are added to some initial thing. okay, so if there is just the initial thing you put in the middle of the screen, that is just the initial object. yeah. as soon as you put a part, there is construct. but it is construct one, because when you add another part, construct one ceases to exist. and you get construct two. yeah. right. so actually defining all of those as the construct is going to be the trickiest thing. it is also going to be a problem, because you are going to have one part to construct forming in the middle of a fixation. right. so it is not going to be quite as clear. right. so you are looking at trying the one, right? and then it becomes a success. and it becomes constructors, simply whatever. and there could be more than one construct at a time, right? there is no thought construct. and then you can start again. you can build sub sub-samely with that. you can link the stuff in. but why does it, why does construct one become construct two when you add something to it? because the... yeah, that is what is always working the moment, because it is generating any id when you try to new part. oh, and this is because we do not want it to stay triangle one. when you start with a construct, it is not a construct at all. it is just a one thing. and we do not want to triangle one to suddenly have. yeah. well, the problem is that all of these things are popping out of existence. so do we know the difference between... we broke it and it went away. and it is now part of the construct. yeah, there is joint events. so if a joint event... if there is joint event linked to the item, then you know, it is become part of a construct. or... can we tag the constructs with what is in them? yeah, the constructs were already tagged with it. so there is actually a subpar of the data format, which says, freeze construct, which two parts made that... okay. so we could essentially... well, then we could culative... or it is a new construct, because it has a new list of parts. yeah, but you can still track what parts went into it. right. so you can still find triangle one, whatever. some fancy prograing is going to have to be done to say, i was looking at triangle one and i am looking at triangle one in construct one. yeah. because the first construct was triangle one in square one. yeah, but that is easy to me, because the... each construct has the ideas for the things that construct it. so now we have to ask whether... so let us imagine this. we have made a construct of two parts. and we are triangle in a square. and we are considering now adding something on to the side of the square that is not attached to the triangle. okay. are we looking at the square? are we looking at the construct? yeah, that was the next question i had. yeah. you will be looking at construct, because that is not it. in this definition, you will be looking at the construct. yeah. there is not a way to figure out that you are looking at the square rather than the triangle. well, we will be looking at... yeah, we will be looking at... the last thing is that we have the echo... the echo traces from the ascii format. so if you want to be able to say i am looking at the square instead of i am looking at the construct, it is possible to get that data out. it is. yeah, it is not doing it in the draft challenge at the moment, but i can easily add it to give that information if you want. okay, because that is the example... presably that is the best example of overlapping areas. because if the thing... the two things are now about it. of course there is an area which is kind of a compromise to them. okay. so what i am trying to run through in my head is that we can always tell the difference between something going out of existence, because it is joined a construct, something going out of existence, because we threw it away. suppose we pick up... we screwed up the first time we put the triangle with the square, and we threw it away. we decided we did not like it. and we took another one. is it triangle one? is it triangle one prime or something like that? it is the replacement for triangle one. yeah, if you create a new part, it gets a new id. so if you drag a new part out, it is a bit... well, do i know what it replaces? you do not, because you would have to have han coding to do that. you would have multiple triangles that you broke and you want to know which one they are planning on using it for. this is true, but if i have triangles one, two, three, right, and i throw them away, any triangles i take out are two, place one, two, three. well, you know which mold they come from. and so, you know which shape they match, but you cannot possibly know which one of the ones they are meant to replace. yeah, i mean, you do not... you do not know which one they are meant to replace, but you know they are not meant to replace. you can either have them thrown away. they cannot replace... the new parts only appear when the previous one is broken. right, so the new parts are replacing those which have disappeared from the screen. and if there is no one tr1 track, the tr1 track is gone. oh, so there is no two parts with the same shape? oh, there are many. we are same shape, but not the same shape in color. same identity. oh, the same shape in color. right, okay. oh, is that true? you have decided not to make all the triangles really square. that is what they are at the moment. okay, so you cannot tell what is meant to replace them, because it is the same... it is just in case of the mold, right? yes, that is the way it works at the moment. i asse that is how 9mg had set it up. okay, so... that is back to... so there... tim is... yep. so shape plus color. they are individual... they are unique. yeah, all the parts are unique. so we are hang on, that makes the task a little bit easier. yes. right? 10g, a much easier one, you can see... all the lines. so... it is just a construction task rather than a puzzle. indeed. which kind of leaves you with an obvious way of making the same task harder. and easier, does not it? yeah. but... this also... that is hard to code. i mean, that is really a thing we might do. okay, so now let us make sure that the coding would survive that. it is just... it is a beautifully controlled situation. the construction task is essentially the same. it is the figuring out stuff that gets harder if everything is purple. for just to choose a color at random here. yes, i think the ending is probably the same. the two triangles, is not there? there is two identical triangles in the tangram. yes. at the moment, there are two small ones and two large triangles. they are actually the same physical size and shape. at the moment, they are in different colors. that also means in the new parts list, they are there for, you know, two large triangles and two small ones. whereas in the revised edition, if they were all just black, they would only be one more in the new parts. when you specify these things, do you specify the molds? or does it figure out what the molds are based on? so is this hard-wired-in-the-tims prograer? is it just an artifact of the way we... it is hard-wired. yeah, yeah. when you specify the molds in the... in the file that generates the parts, we have got list of parts. the molds are based just taken out of the file that generates the first-first parts. right, okay. so, so, how many parts... how many parts are in the file? how many parts are in the file? that is how many parts are purely in the parts box. but if you have five black triangles, they are going to be five black triangles in the parts box or one. if you have five black triangles, they are going to be five parts in the five black triangles than the parts box. so line the words that you need for. in the initial configuration, you can reuse a triangle. so if you only want one black triangle, you used create one black triangle in the parts box and then reuse that black triangle five times in the configuration. -h. as long as this is possible. so i mean, that just is a kind of thing, which is so simple, so much like a single. yep, same. one zero variable change that it did. but what would the written code be? because i am trying to map this onto baufix. and baufix has multiple, you know, all the nuts are red or all the flat things. what colors can have different nuts? well, the same part, the same part is different colors. oh yeah, yeah, but they do not have enough to make unique. no, i mean, there is more than the multiple pieces are the same. so why when you say a red nut or a green bolt or a long green bolt, then there will be lots of them lying around. i think that is how the robot is set up too. five green bolts. here is one. i think we have got to the point where, you know, to try to smarize, we think tim is program can do both of these conditions that you want. but i am still worried about what the effects are for analysis because you were aiming at something in the gdf format. and i was not quite sure what. so all i am doing is kind of worrying out loud about all the things that will happen that will miss by a simple view of, for example, regions and looking at triangle one. yeah. when it is triangle one, not triangle one anymore. so, okay, so i will smarize what we said about that part. every time you cast off a new part from a mold or, you know, every black triangle has a different idea. and you know it is a black triangle because you know which mold it came from. yeah. but you do not know which part it was intended to replace on the screen because you cannot mind read. it is true. so how can we define the shapes that people build? what do you mean define? well, if, assing i was, for a moment, i was jp and i wanted to know how they actually went about building a thing. okay. and i wanted to look at the strategy. and i wanted to see if the strategy was different when we could talk about it. and when we just picked up whatever, i mean, i suppose i cannot talk to you and i am doing this task with you and i cannot talk to you. the thing which is going to be hardest for me is making elaborate plans with you. i can reach for the next thing and you can go where i reach. but if i have some, you know, subgoal, some long term subgoal of doing something clever with putting these together because it is hard and putting these together because it is hard, it is going to be almost impossible to convey that to you. and the difference in the history of construction is an important thing and i wonder how we can get that information back. i think that this is a han coding that is part of the action coding because i do not see how anybody but a person watching this can guess why they cast off this thing at this time. why is not, that is not the question i am asking, the question i am asking is what is the history of the construct? so you have the names of the things in there and you have two constructs, suppose we have two sub constructs and whichever one had two pieces put together first is the earlier nber of those constructs. how do you tell the difference between adding a piece to this first construct and creating a second construct? when the final construct, the way the constructs are defined in the file, you have got your parent construct and the parts that are constructed out of. it is parent child relationship. the child can be a part or it can be none of the construct. so construct two, construct one is red triangle and green square, construct two is two green squares. construct three is a red triangle, a green square and another red triangle. i have looked at the construct four but that is okay because they all have different underlying part nbers. and when you say what a construct in, so how are we going to tell when, for example, you think we are going to have to do han coding and when two sub constructs are put together. no, that is a definition where the construct has constructs as children. yeah, the join action, the result, what you need to a construction part, two parts and whatever you take together. construct. you have got time when that happens. you can see that construct appeared at that time. and you can still track the children of that construct. so we can zip through this and look at all the all the interactions in which people built subcontract constructs first which we expect them to do as a wild hypothesis more when they have verbal counication than when they do not. okay, and we can do that by simply searching for any constructs that have constructs as children. yeah, so we can easily look at things like that automatically. it is just the why they get new parts that is the problem for us. we cannot, if they suddenly, if they decide to get a part of a mold, we do not know, we cannot know why until they do something with it. if they, we have not actually made a rule that you cannot collect extra parts, right? extra parts do not appear, so you cannot collect them. oh yeah, you said that. yeah, there are, there are, it is like grayed out there. yeah, but you can see the mold is there, but they do not come filled. no, no, i mean, you have to break one to get one. yes, okay, you can, but you can break one. when you break one, you do not cast off the mold yourself. it happens automatically. yes. oh, okay. never mind that. it appears and then you like it. so they just have to use it. yeah, the new part lights up sort of thing. oh, but they have to drag it. i will pass the mold one. yes, you have to bring it to play. and you cannot just bring extras in case you know screw up. you have to screw up first and then you can bring it. yeah, that is one thing unlike the, see the bow fix or anything. yeah, there are not any extra parts and at the moment the software does not. but it does have replacement. yes, replacement, but no superfluous. so you can have a standard stock of extra parts that will never use it. okay, so this why question does not even arise. so you appreciate, you appreciate the cost. because you know what they are going to do with it when they decide to move it past the mold line, they are doing something with it probably. and you will know what they are going to do with it because. yeah, but by the time both of them are doing that, they must have already broken something. so you will love what they are replacing. okay, is there a way of telling the difference between intentional and intentional breakages? how would you do that? intentional hole. in the sense that they break deliberately when they bring them into the new parts. yeah, it is like the trash can idea. they both put their hands on a construct because they do not like it. yeah, but there would be no way of cutting that automatically. right, how could you possibly do that? you have to hope that there is language in one of them say something. but that is a han coding, right? so that just does not be coded. there is no way you could tell that just when they are. the role movement or something. so not generically. because if they are going to do it by gesture, they will build up a convention. so that is going to be a particular problem for jp, right? remember all the things we are looking at are with language and without language. and it is going to be very difficult to tell whether they broke something intentionally without the language. which means that they develop a convention. suppose they start off with language and then they say. yeah, okay. but this is probably part of the action coding. sure. so we just just want to make sure that we make a wish list. right. wish list. as a side effect. i am trying to remember if the people deliberately break things by moving two pieces together. they do not break. they do. if one person is dragging a part to a part that is not that part that is just sitting on the screen. there is not being touched. they both break. so the intentional thing is when they actually both click on the same object. and it breaks. for sure, you know, that is or well, it is not necessarily intentional. they could just screw up. yeah, but they could discuss to set it a break something. yeah, i do not think that is very good. no, we will never get away with that. we will get a bad score. let us just throw that away and start again. yeah. wish we had fixed score problem. have we? oh, yeah, yeah, it was through the rotation. oh, yeah, percentage score. yeah, so rather than the nber of panel please or some like, no, the score. it was the percentage overlap and that made the score. that is that is a week is work. the problem was to do with the. no, which which they had real to and absolute peace and it is all to syetry. but that is not the fight. it was not it was not a bug. it was a do not tell me it was a feature. no, it is them just forgetting to find something that had to be. and the dutch lock. yeah, yeah, which is probably a docentation fault. it is in the docentation. but it is like, it is quite a long page. yeah, of course, it is quite media problem. not prominently flagged. yeah, exactly. a counication flaw. okay, so we can that is now just lovely. is there any crazy? well, one last thing. is there anything else you want to tell us about the prior part of this, which is the, you know, what else is holding you up from? oh, well, yeah, we should go back to the beginning. the camtasia was tested last week and initially we were a bit worried because in the old version, it seemed to interfere with it. -h. but when you when craig reconpiled it into this new version, it seems to work fine. yeah, right. so it does not slow down the eye tracker. does not do anything nasty. so we can tell. so we pay for it. there is very small graphical bugs, but it is not it is not a big thing. it is like color white pixels in the course of it in the course of a cause of a task. so it is it is nothing to distract. nothing important. nothing big enough. they are going to look at it. right? no. all right. so the last, i think i am sorry, you know, i had a sort of emails from you and i probably did not catch everything. the problem was that there are two temptation records. yes, they will now have to be two camtasia records because each person actually sees a different screen because of the gaze. they do not see their own gaze. they see the other gaze. yeah, the other gaze. so they will need to be two safer camtasia videos. yeah, yeah. oh, do you need two copies of camtasia, do you? hopefully. officially or the question is the release of camtasia where you just need one editing thing and two recording things because the recording, the recording program is just quite a small program that just generates the video. so i do not know if it is having a look at the licensing for that just to see. so you are going to look into this, right? yeah, i had not thought about how to asse we just get one and one license could run a lot both of us was technically she had two. well, look at the license conditions. it might not. i suspect that it will be per machine, i think. i never prejudiced licenses in club rhythm. okay. i will have a look at the actual camtasia license. the other thing we... well, and hold on before we get going further. so this has implications for data storage, right? because we have got... well, no, this is three times, right? because we have got... oh, no, we are going to build... we are going to use joe is script to build the videos on the flight, right? because it is fast. so the permanent storage is just the camtasia stuff. so... is that a problem? where are we putting things? is there such a thing as a dual track video? because you can certainly mix things. what ideally one wants, one does not really want to have these things. because we are using them for backup and for coding. we do not really want to play them. we can play them, in fact. and, in fact, we would almost always want to use them in exactly in parallel time-aligned. you can dp them into one video frame if you do not mind losing resolution. but that is maybe a problem right. well, the other problem is camtasia has to be manually launched and both machines separate. so the synchronization is going to be a problem? yeah. what are we doing for synchronization otherwise? during the task, there is a flash in a bleep. oh, i mean, not during the task. before... before we... yeah, but you are not asking, yes. okay, so that we would have to realign them. we could not yes. dp them from their start points. well, maybe you could. the thing that you are dping them onto just starts running with flash in the bleep. you turn on the two copies whenever at different times. but there is still... no? is the... what are they? i do not really understand the parts that are operating here. camtasia is are turning on. there is no timestamp that comes from some coon source. no. they are on two separate machines and you start and end them separately. they are not talking to each other. they are just recording. you start it recording. it starts recording what is in one screen. and you start the other recording on the other machine. so... and they are... they are totally simply doing all the other ones. these are backups, right? so the flash... so the flash... it allows you to hand synchronize them later if you need to by stripping extra video off the front. as long as you make sure you start them before the flash, then you are fine. but there is a cost of having to go to backup, which is synchronizing them. so they will include things like the itracer calibration. yes. which is not a bad thing actually. because sometimes you want to go back and find out if this was just a particularly duff subject. oh, yeah. see how long it took them actually. that is true. how long did it take them to calibrate? yeah. every time we calibrate it, how many things... things before the validation worked or something. oh, okay. so you should start the camtasia really early, right? well, yeah. at the moment that is why i was assing... right. okay. no, that actually saves you hours trying to make somebody is data smooth out when it will not. because... go back and actually, yes, they were crap. that is a technical term. technical categorization and psychological research. , yes. the other thing we are getting sort of date was the microphones. because only one of the camtasia videos will actually have the same track. and that is because... , we are just getting... we have got one cable and two mics. it is supposed to be. well, we need sound recording. right? that is... that is two track. that is... yes, so at the moment, it is in... what we have finally... just at 12 o'clock today, looks like we have got it sussed. is to get... one channel... one microphone for me in the left channel and one being the right channel to merge into a stereo... -h. so, a whole file. , unfortunately... on what? sorry. on one... machine. on one of the... the display pc. the camtasia video. it is... no, or... move the... multimedia... that is not what you are putting it. i mean, that is our only sound record. yes. well, okay, you have got the proper sound record, but you are not dping it... through camtasia to record it, right? you... yeah. it is camtasia that is recording. what... before we were going to use camtasia at all, what... what were we going to do... what were we going to do with the sound? -h. yeah. so, , ... is there any sound degradation that comes about from putting this through camtasia, rather than running it at straight? no, you got... yeah, you go exactly the same access to sound quality as you got from anything else on the windows. so you can... you can decide whatever quality you want. so... okay, so what you are planning on doing is bunging it on one of the camtasia tracks, and then splicing it off the camtasia track. it is an easy bit of... yeah. and then you are going to bung it on the other camtasia track too if you need it, right? but we will just... we are going to store all three separately. then... and the sound is going to start at the same time as one of... that arbitrary one of the camtasia videos. but you will know when the real experiment... you will know the relationship between that and the itracker timings. , yeah, because the... the... , yeah, because the synchronization, the audio and visual synchronization comes at a specific point in the itracker file. yeah, no han intervention required. it is timestamped. no, it is... it is stamped into it. so it is just after it prints the line starting experiment. yeah, i am pretty sure it is... yeah. but hold on, do we need that? i mean, i thought the way that tim had this set up originally... the audio... the timestamps used... there would be joint timestamps between the audio and the itracker. so that, you know, the audio record... 10 seconds in was the same as 10 seconds in the itracker record. so that we did not have to do any extra hand work, you know, any chopping the starts of audio signals to get. there was nothing... okay. so we are relying on your matlab script to get us the chopped version of the audio, right? , well, the matlab script, , based just says... yeah, it gives you the time of the audio beep in this end signal. right, so we can either adjust the itracker track data or we can actually chop the audio signal. yeah. take off the first, whatever, 70 seconds. there is going to be a way to sooner or later to align the itracker, camtasia 1, camtasia 2 with two sound channels. yeah. yeah, but , but , lining up the camtasia 2 is going to take... we... he is working on a matlab script for the sound, but not for... so the one that is got the sound on it, that will also tell you where to chop the video to get it to line up. the one that does not have the sound on it, it will not. oh, the beep will find... oh, so it is just the bleeps. oh, okay, so... no way. no hand for synchronization required at all. as long as the scripts work. right? yeah. that will be basically the only thing that is going to be... ...that is going to be the same thing. okay, how confident are you about the... ...finding the script? yeah. okay, how confident are you about the... ...finding the script? yeah, that is the same thing. yeah, that is the same thing. okay, how confident are you about the... ...finding these things? break off the... you have seen them, it was... yeah. so we just have to... ...hope we do not have any subjects with odd vocalizations. yeah, i do not see them with 10 hickaverts, but you know... they also tend to have a funny... ...funny shape. beeps, so... yeah. okay. yeah, because this is the dropout test. yep. okay. is there an in signal? when you decide it is all over, does it... yeah, the signal at the start and the end of every trial. right. okay. so when you have... ...prest were finished. yeah. ...pings back at you. yeah. okay. it is just that all kinds of crazy things happen when you are... ...saving a percentage of a trial. sometimes a good, you know, being able to do that is sometimes a good idea. okay. oh, yeah. yes, it is a stereo jack. it is a stereo jack, but it is a mono... ...microphone. you got a solution for that then? lining. let us go through a line. so it is quieter because it is not... ...so it is not powered, but it is still... ...yeah, we still pick up the signal. you should... there is not a better solution that involves... yeah, i think we do something better than that. because, you know, people might want to use this first. be sure to recognize something. you never know. the date is there. yeah, i mean, it is crazy ruin and anticoach. which we specially build in anticoach. yeah, it is on dead in the room, which we specially build for this. and you are going to want for a line. we should not screw it up more than we have to. is there anything we can do to improve this? oh, no. well, no, no. better to collect it sort of... ...with the powered microphone or something. well, when they are out there, they have batteries in them. but it is not... there is a... ...the thundering pad because of the lining out inputs. so, i thought a bit of solution was fixing this problem with the mono microphone. socket. sound card? so, you said the problem was the... the sound of the sound... the sound of the sound of the stereo, the input is mono. right? the jack that is plugged into is stereo. but when it is recording for microphone, it records in mono. so, is that fixable? like, is there any way we are in the sound third? yeah, and these are good. i think the new sound card sounds a better solution than munching about with trying to filter white noise out. oh, i think we will remember the old sound from the... well, the old sound from the 10th of... well, i suppose one thing you do is record the speech, single-separate for each person, but then you have to pull the two sounds together. which is not hard. but if each machine recorded, we could record it like the... so, i think you have to align the videos anyway. right? yeah. yeah. put two on us and do a stereo signal. yeah, see easy. i am not a technical person. if not, if not, if not, if not, if not, if you are not, if you are doing a matlab script, you just read file one, read file t. and then... so, is there any reason why we do not do that? yeah, but then the matlab script will tell you how far apart there. because you can just measure the drift between the two of them. so, you get a list of where the beeps are. and then you say, right, this stream is like i do not know, 0.25 seconds behind the other one. says robin thinking about cutting and splicing. yeah. yeah. well, it is... in the old days, we probably would have... if they would been in the same room, we would have read a little stereo thing. my background is back up as well, just to make sure. because it is slightly dicey, you know, if his scripts do not work, then do not get the old one. i want to see one of them look really nice before we start running the subject. do you want to do that? it does not have to be a real trial. it just has to be two guys talking in the two bits. and then i just want to know it works the way you expect it to work. this is not a gesture of mistrust. this is just experience that if anything can screw up, it will. we have both been so badly picked in the past. i am trying to choose my language carefully because we have been recorded. you hear more choice language at the point when we have all been a lot of work. then we discover we cannot use the session because of something we did not think about. yeah. but this sounds reasonable to me. so i think... do you know if they are body-sector things? -h. do they both have the same sound card problem? i would not count on it. do they both have the same sound card problem? i would not count on it. they both got the same sound card. okay. so... yeah. it is probably worth mentioning this to the guys in the garage in toronto, right? to save. yes. yeah. so the external version has plugged that size. -h. and that is stereo microphones. right. yeah. the other one is like the smaller size and that is not stereo. so the card can do it. it is just that the connectors on the connectors are the back of the computer. come. well, yeah. i think tell the guys... i think that is a... if the docentation said it could record in stereo, then i think we should talk to them about how they have done this. you are not sure from the docentation what it says it can do? the bottom trouble is finding it. the question is, is it as much of what the size... yeah, yeah. yeah. but as far as we can tell, when you find the website of the cravalize website and the review of it, , and they were not entirely clear, but they both suggested that it was a monomacrophone. yeah. i think it is not the people i think you can put it into the other... yeah, it is just the way they are wired it. so it is getting late and i have got a two o'clock and i have got a nice lunch. so i want to eat my lunch today. what did you want to get through today more? i think i was useful going through your expectations about this because that is quite a bit clearer in my head, at least. yeah, but i think mostly we leave you to go away and redesign the gdf and add new bits to the gdf along these lines. yeah, so basically the output gdf is just going to be a whole series of events. yeah, we are starting in time and the event is going to have whatever the object is that is been looked at and things. and then, yeah, and then it is a matter of we can put whatever filters we need after that so you can say, right? i just want, so you can say, from the time where they picked up triangle one to the part time it became part of the assembly, find out how much how percentage of time they were looking at it or whatever. okay, so given that there are these events recorded, we can use any of them as the beginning of any of them as a start point, for example. there are also motions being recorded of objects. yeah, so you have got movements, there is look events, there is fixations of blinks in there at the moment as well. and yeah, and oh yeah, and say, yeah, look, say, look, say objects, look, whatever else. but i think the thing to do is have a few to grow away and think about it this way with different tracks, with different objects and the, there are kinds of things we have added about whether they are looking at the other person is gaze and what have you. and try to change the specs so it reflects this and maybe, maybe by that point there will be some sample data or something. and the right thing to do is first to look at the spec the way you understand it now and some data. and then alan will have new ideas about what is needed or about these post-analyses, you know, and then we can add them in. but it is going to emerge over time, that is clear. that is great. i before we break up for lunch, i just want to make sure that i know how long it is going to be before we run mode. okay, so the sound thing is, it stands in our way, we need to be recording sound online. okay, so that is the thing that has to be solved. the shape thing is solved. yeah, that is that is solved now. we think, yeah, test, we believe. we have to test, so that is that should be done this week. in fact, like tomorrow, for example, all the shape problems are solved, generating shapes, no problem. scoring, shape overlap, no problem. nothing is a problem. there are no visual displays. you do not have your models. yeah, they had their inspection last week, jp staggered away from it. so, the moment you understand what you think is going to be like that. so, the moment you think that you are going to be like that. yeah. because i know you are going to trigger it. yeah. well, anything you actually need fixed. you know, in that case, joe does not live here anymore, right? well, but he was not going to be booking any time to us after the 31st of october. so, that means that any bugs that need fixed in our corrects responsibility, right? you do not know how many change on that, right? that is what he said to us. i need to discuss with him. i would asse, you know, no more contact with joe. it is not fair to get work out of somebody for free. so, you know, ask craig instead. well, he is physically here. we want to pay him for some more time. you can do that. would that be a just better use of our time and get? yeah. well, he was not paid in advance. he is being paid in a rear. so it does not matter. i think he is around and i believe. and if i think it is better to have all the software, i mean, it is not big things. it is just maintenance of this program at this point. but if everybody has a lot to do and, you know, joe could give it a couple of hours, which is what it might take just to fix it, then let us do it because starting run time is not going to be. yeah, if you can give it, you know, like, because the problem is you have got to have it iediately when you discover bugging that. and we can make craig shift all his other priorities to do this because we bought him. right. but we cannot. we cannot make joe do this. yeah. so it is kind of between availability and speed from start to finish, given that this is somebody else is code. but it sounds like you do not think there is anything that actually needs fixed at the moment. because we only need this to work well enough that you can use it for something. right. we got what we are building models. right. how many models do you need to completion and how long does that take? and you got. well, and you know about complexity. you are waiting on malice. you can. cold call her today is after me. yeah. i think so. i have to check back with. with jp fairly soon. ok, he wanted to. the next 18 month plan. great. deliverables. great progress with the experiment. well, that is what we are doing now. ok, so what do we think if you have a fairly hectic week? are we looking for subjects next week? i think. ok. adds go up. yeah, i do. i do. but i think ad should probably go up this week. we want people for next week. is that ok? is anybody now terrified at the thought that we are live next week? there are people coming in here. one after another or two after two. more likely. ok, is this generalized generalized anxiety robin or do you have a specific thing that. ok, so aside from the usual angst which we all suffer when we go live, so we want to do some piloting at the end of the week. yep, yeah, so we will get we will get the audio stuff tested for single mic friends. yeah, get that test in a little basement. i asse that is something you need me for in terms of that. right. oh, yeah. but she is actually relaxed that somewhat. ok. yeah. ostensibly book time which is not. so you can dash in there for half an hour at a time. does it sound very useful for you? ok, well, ok, we have a solid booking for all the mornings anyway. right. and except by permission of us. all right, we own it. so we can change that and everybody acknowledged the other week that we that we have. but it would be kind to tell her ahead of time which of your one accession is your ball. yeah, yeah, yeah, yeah, yeah. do not worry. there is a booking system. right. so it is public. what is booked in one of these? i thought that was the problem that your mornings were not sliced off on a booking system. maybe you should get on the book mornings as far as the i can see. does you know if you are sat told use the booking system? well, we think we spoke to all the people who use those facilities the other day, but we could be wrong. yeah. and one of the people upstairs downstairs have, you know, as rules about who you hand the keys to. well, because you know, we like people to know to ground the. oh, i thought the lending for the book system. caroline. from caroline or the general office. see, because you are supposed to have training in, but no, they need they need an account on this machine to actually use it. they need account on the machine. so that is the thing that they could book. they could not actually and you control those accounts. okay. that is fair enough. okay. okay. we are also working on a way of making sure that the machine is returned to zero state when they are. -h. yeah. and you come off. that is a because it is because then they love the first time. well, people have been leaving various bits of who knows what around them. right. which we think is what is critical. yeah, yeah. okay. i really have to get out of here. so, , what, what else is important before you run? nothing. all right. piloting, piloting, piloting. you have, we have to build up the things we have to try the machine. things we have to check them with marlos and jp that they like the representation of the variables. right. how about, you have any time on friday? oh, i do not think i brought my diary up. , but maybe why? maybe why? you know, back. maybe you and i should be the pilot subjects. first pilot subjects, the ones who know which questions we want to ask. and then we should get another pair who are naive to the whole thing. okay. so. yeah. this is generalized floating anxiety. no, no, it is it is it is it is a wisdom, but yeah. well, , because actually we can, you know, we make coents. they feedback and a vote into the development. h. so do you know what time of day you might want? because i should, i should check that. okay. you do not, you do not mean me involved in the pilot, do you? well, you all have to, unless, unless the bug report, yeah. you will have to be there too. oh, yeah, i will be around, but yeah, i want you to. hopefully it all runs within, yeah. i can relax. okay. so that all sounds good fun. well, i can just leave you guys here, you know. hm, why not. be, oh now because that is the... yeah, but we will tell you later. yeah, we will tell you later. what are all of the things? why do you know that there is no such thing? and then you know, so, hey, look, i am dr. andrews. i am the journalist in the industry. i think that is the offensive of the job services. but this is the job service. there is no job service. i am not sure if they protected you. or james. he has a tag that he loves you. i have heard he has a tag that says, but i am looking forward to it. and he is going to be the biggest tag. and bob logan is... i am not going to be the biggest tag. i am not going to be the biggest tag. i am not going to be the biggest tag. yeah, i am going to talk to him. i am going to say that he is the biggest tag. you think? there is something wrong with him. i am going to say that he is the biggest tag. he is the biggest tag. i am going to say that he is the biggest tag.

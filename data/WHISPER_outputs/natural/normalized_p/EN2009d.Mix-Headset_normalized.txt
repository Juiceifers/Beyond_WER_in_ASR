which data man, you know, yeah, i want everything and then i'll decide what i want. so this was that face-to-face meeting, okay. but it doesn't, there isn't, so there are things in the abstract record that we definitely don't want in the gdf format, like the frame rate eye movement. you know, we're expecting the gdf format to be sort of a parsed version of events. and you know, there's just too much raw frame rate stuff coming out of this. you wouldn't want it in this kind of format for a translation data thing. yeah, we always get that through. we're not throwing anything away. we're not throwing anything away. we just decide to re-jig this at some finer method. we'll still have the original end a method of filtering. but the way to think of this is, this is the data that we want to be able to analyze against the other tracks of data. so the data that we want to compare with the language or with whatever. so as long as the format in which we pick it up is a format which could be generalized to a finer take, because the worst thing that can ever happen to you is you discover that you've done huge amounts of analysis and you actually had the data. you threw it away because you treated it so grossly. yeah, okay. so in essence, whatever we should be able to backtrack and say, okay, instead of every second, every tenth of second or some such thing. well, we're not doing frame rate at any frame for, well, maybe we are. i don't know. i had thought we were, yeah, the eye tracker does. right. well, the kinds of events that we had before talked about putting into the record, but then, yusin, alana, and nxt, isn't based on saying every ex seconds something. give me what's happening every ex seconds. it's more like, give me the fixations and what needs to know the duration of these things, right? yeah, duration would be able to say. is the difference between saying that something is in a particular state every frame, whatever the frame rate is, ten seconds a minute. that's one kind of way of looking at data. and a parsed version of the data, which isn't at any particular length. it relies on this really close frame rate. well, so there's the real time. there's only events. what i'm trying to figure out is whether we've thrown time away. no, no. the time is still in there, but what you want is to figure out what are the, what are the concepts behind that data that you want represented. so rather than saying, the eye was at this particular place here and then a tenth of a second later here and then a tenth of a second later here, you say there was a fixation from this time to that time and that was blank from this time to that time. okay, so one of the formats in which i track your data is analyzed is percentage of time spent on some target as opposed to some competitor over the first second after some event. okay, so you actually have to be have to show at some time slice rate where the eye was on the same target as the other guy, a similar target, what we'd both been dealing with. so we have to, we have all the parts, the interesting parts of the screen identified and be able to show distribution of gaze over time. all right, now we could be really unlucky and somebody would expect us to do that at the real frame rate. but i think that's really unlucky, but my point is that we mustn't throw away or lose the capacity of being able to deliver that kind of data. so the two issues here, we're not throwing anything away, but the question is what tool would you use to get that information out of the data? would you be so the more you can plan, typically the eye will move, right? so over any one second, the eye is actually fixing on a bunch of different things. and so when you say the eye was on this from here to here, what's going to happen is that if you use the real frame rate, it's going to jiggle all over the place. it's going to be on this landmark. it's on this object, that object, this fixed thing, that fixed thing. okay, you're going to get lots and lots of stuff and it's percentage distribution that you're going to want. it's not, i went here, you know, it's like person walking, i went here, i stayed here. it's more like fly hovering. so you need to know the percentage of time it was on during that fixation. because if you take them as separate events, you get thousands of separate events. yeah, but the sort of start and end times will give you that, say, that, as a, and then you just measure against, you know, against big friends. yeah, the cumulative total timer. okay, so the percentage is, it's not something you're using for measurement. it's a cut off for whether or not it counts as a fixation. well, that's the, that's the problem. there are two ways of doing it. one is that there's always a cut off, right? but the other is that there will be a time span, a kind of reaction to some event span. yes, i'll lag in some of it. i suppose there's the secadic movement itself. and so i mean, there are really two ways of looking at this. one would like to know, for example, the percentage of time overall in which two people are looking at the same thing. okay. and one would like to know sequences of, they didn't look at the same thing and then they broke it. or they did look at the same thing and then they did or didn't break, you know, one, one could imagine those two categories. that's, that's a kind of testing of our hypotheses. but there's a certain amount of, um, dues you pay to the way they do things in the literature to get your papers published. and one of the things they will want to know is an event series after some critical event. right. one percentage of time is given to looking where the other guy is looking. and one percentage of time over some, you know, reasonable time span of a couple of seconds. right. so they'll be, they'll want to see essentially the gaze settling on particular incidents, on particular places. so we have to be able to deliver those two things and they're rather different demands. right. the, the should still all come at the little sketch. i asked this for last week about nxt and whether it would have that sort of tiered effect. so you could see the overlap of where one person is looking compared to the other in their mouse movements and things. yeah. that should. because all you want to know is whether they were looking at the same object in the period after. but because it's also based on the, the time course of the procedure, you'll be able to basically get a scan path at the pattern of events from that. okay. can we try it to make sure that that, um, that this is satisfying elements. i did have it somewhere. i didn't have it. well, there's a whiteboard, right? we love this thing. see if the pens work. so, um, this is, um, a's eyes, right? and b's eyes. and i think what you're saying, you should probably draw this. right. is that they, you know, if, um, from this time to this time, they're looking at triangle one. what you're saying is that you want to know in the critical, you want to know after they're, they're looking at triangle one. what's happening in this period with the sky, right? or how? let's, let's imagine a typical construction event. okay. there's some part. there are, there are separate movable parts on the screen ready for use. right. there may be or not a construction already begun. and somebody makes the first move. there's some kind of communication, either gestural, imaginary, or verbal that plans how we're going to do it. before that happens, the person who speaks is going to do some kind of visual scanning. while they're speaking or communicating in some way, the other person may or may not be looking where they're looking. okay. they may be overlapping gaze at particular objects, which are of interest. let's call it the construct, existing construct, which could be zero. right. or the, the addendum, the thing which is next going to be added, next piece. okay. now in neither case, when you draw this, he's looking at triangle one, which you're actually drawing, you know, for the period of time in which he's steadily looking at triangle one is going to be very, very short. right. because staring fixively without interruption, blink or, or saccade is, is in extremely short event. at that point, the lumped, all the individual fixations, as long as it doesn't move off that triangle together is a two-total sense gaze. so it's in a region. it's in a region. that's a target, maybe. okay. but even so, you're likely to get bouncing in and out of the region. right. so even so, you want to look at if we're interested in how long before the construction move takes place, how much of the time they spend looking at the same thing. let's call that our measure of alignment. so they're going to be, yeah, that's right, a is going to be on triangle one and various other places. that's right. and b. okay. and we're going to look at the percentage of that time where they're both in the same region. right. so what i want to make sure is that we don't simplify, do you know what i mean? temporally simplify too much. so that, yeah, i mean, as long as we're, because then you lose percentages. yeah. there shouldn't be anything to see. right. and so b has some periods of looking at one and all, which will also be intermittent because. yeah. so, you know, he might get triangle one there and now maybe this one's going to overlap quite a bit. yeah. so what you want to do is be able to define bigger periods, which is the period when they're sort of interested in triangle one overall. right. this is sort of when they should be. when they should be. if we have an event at that, yeah, the second, like, name for the second before it. and then we can just take that chunk out and do something with it. yeah. but that's that should. okay. that's not something that you can do in the nxt query language, but you can't do that in any, you know, this is such a special purpose. but it's easy enough given the data format for any of these things to do that. so you could do it on, because it's just a matter of the hard part is deciding how close together these have to be before you decide that this is an event that you want to pull out. because, you know, algorithmically, you're already putting together. i mean, this is essentially already, you know, these fixations with stuff in between. and, you know, we've got an algorithm for deciding one that's a look, i guess. you already have that or no? well, it's just based on a stable fixation for sure, or something crossing into that region. oh, yeah, yeah. so it's all fixations. these are all fixations and cots, but within the, yeah. so that's easy enough. so the hard thing is they could be moving their ir betrayally here, right? and, you know, maybe even having fixations on other things. yes, yes, yes, because for example, for part of that time, both b and a are probably looking at the construct. okay, if your intention is to move the red triangle to sit on top of the thing already constructed, you would tend to look that forward. yep. so this is able to, yeah, but what you need to do is we can already build into this gdf format, these regions, if you can give a definition of what you think that is. but i think the right way to do this is to be able to inspect the data in some tool and play around with the definitions, because you won't get it right the first time. yeah, sure. so the question would be under what tool should we be looking at these events? and it allows a reasonable choice for that, right? what you need is something, well, no, because you need to, you need to be able to see the effects of this. so i guess this is a case of craig writing some scripts. so robin having some ideas about what the relationship is and saying, you know, add this data automatically. i mean, it's not that hard, right? it's just there'll be a bunch of these. you'll have some rules about how, maybe how long you spend on other objects and whether the other object is the existing construction or not. right? right. so essentially this, this, a e is divided into tr1 and c and other stuff. okay, where c is the construct of the existing thing. right. so if they, if they, they had a fixation on c, you wouldn't be worried. but if they had a fixation on c, we take a separate, we'd look at the percentage time. i mean, i have no idea because i don't know how people look when they're building things together. okay, so there's a, there's the addendum and the, and the, the existing construct. and i don't know whether they're going to spend more time looking at one or the other. but if they're, whatever it is that one is looking at it, the other's looking the same place. they're in good shape. but you know, they're going to look at the clock. yeah, sure. i'm not going to look at it. and that's what the other stuff is. we're not going to look at it. that's what the diagonal stripes are for. that's true. but we can, one of the things we'll be doing is categorizing people. i take it or interactions by the amount of time people spend looking at the clock. we expect that we put people under time pressure. they'll look at the clock a lot more. but that's like a separate analysis, right? sure, it's a separate analysis, but you don't want to throw it away. right? so, so every step, if all of these things are actually categorized by the eye tracker as to where the eye is, right? you should be able to pull out any interesting category and say, all right, for this phase, it's tr1 or c. for this phase, it's, it's q1 or c. but what we find, what we can get out of the data easily at the moment is at this kind of level, right? and then it's a case of defining algorithmically all these other transformations that you want. so this is one we hadn't thought of adding before, but we should, right? which is, well, how would you decide whether something was the current addendum that you have to actually transcribe the thing or watch the film for the moment? so that's a human decision. yeah, absolutely. yeah. yeah, so, so i mean, once you've got that some information, you do, well, you've got the gdf format, you then filter it to say, right, between time x and time y, they're, they're constructing it, they're adding triangle 1 to the construct. and then you just say, in that time period, what essentially they're looking at triangle 1, what essentially they're looking at the construct? so that's, that's that's that's that's that's that's that's the addendum and the construct should be, you know, kind of, yeah, they, they change their true identity, but they're, they're categories of stuff. now, i, yeah, kind of assumption was that, that this was jp land, that that's what he was, what he was really interested in was the kind of coding which would define the building sequence. okay. so, and the, and maybe he wants to think about that more and say, well, they were several candidates for the addendum. all right. and, and it was the negotiation of which candidate was going to be the right candidate. it's actually the interesting stuff. so i should talk to him about this. he's, he's actually, but we emailed me with a list of things he wants to discuss at length. so, but we, we, jp to be defining that maybe. well, this is my question for him. is he going to define this kind of building sequence in a way that we can get out or see? so i mean, you know, they've been working on construction there for a while. so maybe that they have a coding system that's ready to go and we should just apply it. yeah. okay. okay. they do a lot of subassembly, the tasks they've been doing. so they may well have a, i could believe them, you know, taking an interest in that. well, that's fine. i mean, the general division was language here and other stuff there, right? right. so, i would just do that. right. what? well, we have, i'll just add it back. i mean, actions might mostly be theirs, right? but since we have the, the eye tracker, we're going to have to answer their questions. oh, yeah. eye tracker here. yeah. i mean, we know that. but so they'll, they'll tell us something about that. but presumably what you'd, piously hope, is happens here is what happened with transactions, right? that the verbal analysis and the, and the visual analysis give you the same breaking points, the same chunking points. well, yeah. but i mean, with transaction coding on some like this, you would use, you wouldn't consider it verbal analysis exactly. it'd be verbal plus action. because i mean, but it's a task breakdown. it's just a set. it is a task breakdown. but for the verbal version, there are ways of announcing that now we're doing a new one, right? yeah, but you wouldn't have, you wouldn't do two coatings for task level one. no, you wouldn't have to transaction code in that. one of the things, one of the things you'd like to establish, you know, as an, as an outcome of this is that you could analyze either end and you'd get the same chunking of the material. i don't think that's real estate because i think what you'd do is, you know, you'd get the same chunk. what you'd actually do is use the full record of what you have and do a segmentation. i think it'd be hard to understand what was going on if you use like just the language without which in the video to decide whether we're breaking down the task. it's a hypothesis. oh, you don't want it to be coding based on that though. and then that seems a strange way to go about things. well, the language events are multimodal, right? you know, they're doing all these things together. they are doing these things together, but one of the things that you, one could imagine doing is, you know, having the transcription there and just play it back to a bunch of captive undergraduates. why do you care whether they stop stuff? they can do it just based on the language because essentially you're looking at cycling sequences and discourse. and if the discourse tells you what's going on, that's information. i mean, one of the questions is how the information is going to be shared across these media. and if you can get it all out of the speech, you know, if all of the chunking is available when there is speech, okay? then it's carrying a lot of the burden. well, it seems to me that's more important than the other things one could get out of this data. but, you know, but this is, but it's possible. we haven't looked at data like this with this, with our old fashioned analyses, you know, and it would be really nice to know that much information, that chunking of the task information is being carried by the language because jp's question, the overriding question, is so what's language for? you know, people are busy interacting all the time and all of our colleagues don't even bother to control for whether people are talking to one another when they're doing these joint tasks because it seems to them to be irrelevant because language is irrelevant. it would actually be nice to demonstrate that in a place where we're controlling whether you have language or not, you can get the entire chunking of the task kind of the language. yeah, well, i can see maybe wanting to know whether you can do the chunking just based on the actions without the language in cases where they use both. it's more, i can't quite see why it's important to know that they can do it just based on the language when you know that they have both. because you know it's a self-contained system as opposed to a system which can't be interpreted without the other system. uh-huh. well, i think that was just about to fail. that was just about to fail. almost all studies on language claim that language is a self-contained system which will give you everything you need to know. really? that's the claim. okay. anyway, i didn't say it was true. that's the claim and so it's worth testing. so back to this main problem which is, you know, the record that we are getting in the first instance is about these, you know, they're looking at some region of the screen to find dynamically. and then we need some way of knowing what the, you can see adding these other analyses about, you know, they're jointly focused on this region and trying to figure out what's percentage of time they're looking at it. as adding new tiers of information to either the alon track or nxt, they're both sort of track based in this way. but the hard part is knowing how you want to do that. and i think in the first instance what we're trying to get into the gdf one that is just this and then we've got no option but to figure out a way for like to look at this, just explore this data, suggest ways about doing it and be able to play them back and see when we think we've got these things right. i don't think we even know what the set of these things are that we want much less how to get out of it. and we will then establishing the full set, you know, take us much of the project. so yeah, that's right. so this is not, you know, this is something we're aiming for but this isn't something that affects what craig's programs for the initial gdf translation. my only concern, as i said when i barged in was just to make sure that we didn't lose the things that we might need to pick up later. so let's just return to this question of frame rate because this is the thing we were not planning to transfer into this format. so again, you know, a frame rate kind of coding is, can again be seen as a track but it says everything's coding like this, right? where you say it's state a, state b, state c. but since the definitions of look a thing we're looking at are the ones which get rid of the lower level like chiggling around in the area of a particular object, right? so if we're moving the green triangle, we've defined a region which is dynamically the green triangle wherever it is, we will jiggle around in there but it doesn't matter where we are in there. that's right. but these are level of analysis. you're happy that it's not going to have frame rate like this. it's going to have an interpretation like this. well, that interpretation is definable to frame rate by the only way we're going to use frame rate. what does that mean? sorry. well, i mean, because i can say for how many frames this fixation went is officially defined. so as long as it's not an untimed event. okay. yeah, all events have a start time under the entire time. so it's fine. i can say it's a long one or it's a short one or it's 20 milliseconds more than that one. it seems to me that alan's concerns might mean we need to add more information to these tags because this thing in itself is a bunch of fixations with the cards. so things like fixation, the number of fixations. fixations and the percentage of time those fixations cover you might want. yeah, there's some some measure of the so we could work out the number of fixations that made and the average fixation duration as well. because having long steady fixations can be informative. and so can i have a fixation as percentage of it? this isn't a leading question. this is a question question. why would that be informative particularly? if they're holding there, if there's less dancing around the cognitive focus tends to be in one sort of part. so there is a difference between if they, even though they're still looking at the same part, if they're looking around it and rather than just holding their gaze steady or on it. so you think that for example if they're looking at one or another apex of triangle, it would just make a difference. yeah. and we're exploring the thing. as opposed to they were simply, all right, there is there it is. so that really means that we're not throwing away absolute fixations. no, i wouldn't. they have to throw away. screen location with absolute fixations. but the actual look. no, no, this is still summary data. we're talking about just adding attributes to these things that say the number of fixations that counted as that looking at triangle one, right? so it's possible. exactly. so i understood you to mean exploring the figure because you know, your fixation is point and the figures are bigger than points. so you could be exploring the figure or you could be just somewhere in the region defined as the figure, but not on it. well, yes, but that probably isn't going to be easy to get. okay. because they have to break up the parts. so you just want to know the variability of the fixation. i wouldn't that differ from person to person? yes, it can do, but it's also looking at it within their own behavior. okay. so it's the number of different spots within that region where the i as fix. i would say just the number of fixations. the number of different. so the spots will be different anyway. so it's too high. you're not going to have the same pixel. so we have the option that we can put in an a fixation thing here, right? well, if you want the smaller coding in here, so that it's not just parsed into this idea of which object, but you also have the raw fixation data. we can put that in as another track. if you think that that's something that you might want to look at in one of these tools that shows you the tracks against each other. well, all i understood you to ask for was the duration. yeah, that's all he asked for. yeah. well, i think we've got everything. then as well as it's you can come back. you can always, yes, it's you're not throwing anything away then. yeah. and in nxt, there's no cost right because the you just don't choose to load those. right. all we're doing is dumping it as output that you can load if you choose to. you know, so if the things that you just know are crazy and you're not going to want, then we don't do it. but otherwise we go ahead and dump them because it's easy to dump up the fixations. yes. so it's a number of different. okay. so it's the number of fixations. well, actually, do you have the average duration? do you want the other ones? did you want the other ones? but duration times will somehow, whether it's the average one or. duration of each fixation in the region. not eat? well, if it's each, you have to break it down into another tier, right? you can't, you can say there were three fixations and they averaged a certain time, but you don't want to. the average should be all right to work. well, what about the overall sum of the durations? is that, i mean, which way do you want it? it's not the number of fixations in the average time. yeah, but that's the way you want it, that way around. yeah. so that's a measure of jiggle in the region, roughly. and did you want the percentage of time fixated, as opposed to, which is sort of another view of this number? you can have as many of these as. you should be able to derive that presumably from. well, it's not, the extra cost of having these as attributes is not high. so, you know, it saves you having to do, right scripts to do arithmetic on that later. if you know that these are numbers that are going to be useful to you. what's our error of measurement on location on the screen? so to what degree do we actually know whether the two little eyes, little circles are exactly in the same place? or just somewhere in the same region? it can vary a bit depending on the calibration. but we're building in a sort of error margin. we'd be some pixels around, but there'll also be a minimum one, because i'm trying to think it's probably the small, the actual mouse icon is so small, it'll need a slightly larger, just because it's, yeah, okay. so a larger area of error margin around it. okay, so my question is going to be, the mouse is a dynamic object, right? the eye track is a dynamic object, or is it only the piece that the other person's eye track is on? that's an object in this definition. no, the other person's gaze position. is an object. okay, with some, with plus or minus something or other, yeah, around it, some circular area. and so you can be on the object, but not on the other person's gaze. so there can be a triangle, which has, so if there is gaze in the center, and your gaze actually happens to be here. yes. you're in the triangle region. but not looking at their individual. but they probably will avoid looking directly, if they're looking directly at it, it's obscuring the part. but it's directly at it when, when these two, in this situation, when these two overlap, right? like this. yeah. yeah, something about that's going to cut that, because the program we've got there is just in it, they're only looking at one thing at a time. so whether it's triangle or whatever else. so what you're just saying is, they can be looking at the triangle and maybe a nice point and maybe an eye at the same time. well, it would come up, it would say yes. right? i mean, because they would be in the same place. so if you, you're going to have dynamic regions which overlap one another by definition, if the mouse is on the construct. the main thing is the trees and then the trees. yeah. well, those are different tracks of information. so what you want is one track of information about which object it's on. what about whether or not it's something other guys gaze and what about whether it's on one of the mouse. we treat those as other objects, but the difference between them and the parts of the thing to be constructed. is that they're allowed to overlap with other things, nothing breaks. okay. yeah, but in the analysis, you should treat those as completely separate tracks of information. because they can be looking at, they could look simultaneously at somebody's mouse, somebody's gaze and some object. right? yes, as opposed to simply looking at somebody's gaze when the mouse isn't also there. right. and you want to know those things. so these are independent. right. so they're independent dynamic objects. so what we want is whether they're looking at the other person's gaze, right, and say they are in this period. well, i mean, it's okay. so a definition of we're all looking at and touching the same thing. so imagine that we've just added a piece to the construct. all right? so now that's the construct. and both mouse symbols are on it. right? and both gazes are on it. yep. right? so at that point, you should have a lineup of a is on the construct, a is on the mouse, a is on a is on a is mouse, a is on b is mouse, a is on b is on b's gaze. and b likewise. yeah. okay. so there's a lot of tracks here, right? because we just did a this fixation track. and then there's a's mouse, not their eyes, is on an object, right? and the mouse might be on it. yeah, but the mouse is also triangle one dynamic object. but it doesn't matter. that's fine. okay. the mouse, which thing, where is the mouse? you know, it's on this object. and a's eye is on, well, a's mouse, i guess, right? a's eye might be looking at a's mouse here. a's eye might be looking at b's mouse here. right? i mean, these are all the different ways of taking cross products and the things that could be collocated. so you just treat them as independent. and then you look for combinations of them. yeah. i'm guessing from what you're saying, you want all these tracks. i think we need to. yeah, we'll just find a measure of the line. and looking where the other guy is directing attention. and there are two measures of where the other guy is directing attention that you get from the visual track. one is where the mouse is. yeah. the other is where the gase is. so you kind of got the idea here. yeah, yeah. yeah. so, yeah. so it's just a matter of adding the two mice pointers and the two gase as extra objects. so, yeah, some of the songs i've got an id in there. we can just say, right, at this, between these times, they're looking at that object. or the look of the mouse, the look of whatever. but the important thing is you don't treat the entire set as mutually exclusive and exhaustive. it's just so that the object is like a separate level of analysis. it's what if it were going to be objects, then whether they're looking at the gase. but it's also going to be the case that whatever region you define as the region of the dynamic object of the red triangle may get to the point where it overlaps the region of the dynamic object of the green square. okay. what do we do about that? does that happen? yeah. because if you have them close together, there's always some fuzz factor around there. and so if they're left lying close together or in fact in the model, in the not in the model in the supplies set, they're actually neatly packed into a little space. okay. so what you're saying is like a new problem for us, which is. so if your objects close together, your i gase can actually be looking at the left edge one and the right edge of the other. they're looking at two objects at once. yeah. so you're saying. sweet. sweet. okay. can you write on my pen pad? just to say, yeah, pens. whiteboard pens. so you're saying, you know, they could be looking at square one at this point. because they. because the two are so close together that their regions overlap. okay. that's a problem for the data models and either the things that we're using. but unless we just define it as. there's only that they are exclusive and whichever area has a greases overlap is what they're actually looking at. what do you mean by greatest overlap with one? if you've got your sort of eye position and it's. it's unlikely to be exactly 50% or one object 50% in the other. draw it. my special reasoning is no good. i think i think it's seeing information. i'm the one that uses the whiteboard because i actually put the microphone. yeah. what i'm i'm thinking is if you've got. see one object there and. you know, so this is the better pen. okay. part one and part two. and you've got their sort of they're looking. there. uh-huh. then that overlap means they're looking at two pieces simultaneously. yeah. but you had a way of choosing which one right? yeah. and that's the idea is more of it. it may be a bad idea. you just throw it in a day. yeah. that's a decision. well, the thing is that i'm saying is if they're looking at most of what their overlap is here, then we stick with that one. so you just mean which is it closer to the. is the circle and what is the circle they're looking at pixel or something right? no, that because the gaze position will be a sort of fuzzy area. it wouldn't just be a pixel. it will be an actual. like a circle and the area. the gaze will wobble. so that's that's going to be. it's. so that's very a size. it's a sort of lump. target. so there'll be a bit of a. some sort of overlap. two objects. or indeed they might be looking from one to another. yeah, they're. yeah. it's just like, you want to choose or thinking so you don't want to decide it's only one. the only thing is the only gds for it's working at the moment. it's actually got separate track for each part. okay, well, that's fine. that i was going to say that's the obviously. oh, but what? yeah, that's going to be analytically because it's going to. is he has to know how many parts of it? well, it depends on what you build and there's different parts of the different parts. whether you do in the tangram way, they're playing or whatever. six to a dozen. okay. the thing is if we've got to see the track. i know ways of getting around the track. we can easily analyze it down. play it wrong. i mean, i think it's very likely that. i mean, if the other oscillating thought then that's presumably going to change the week. so you are actually going to see them flipping between. well, not as the regions overlap. if they're really close to the region, it's going to get fixed. yeah. and if you define the regions so neatly that there's, you know, that we're losing gaze because of jiggle outside this closely defined region when it's in the middle of space, then. i mean, i actually like the solution. however, ugly it looks in terms of a data format of having a track for every. yeah, well, the data format i'm worried about. it's the way you do the analysis because you don't want to have to say, you know, did they jointly look at triangle one? okay, did they jointly look at square one? okay, did they jointly look at, you know, you need some way of going over the whole thing, but we can find ways around that. i think for now we do it this way and then we think about what we need out of it in the end. it's just, you know, in a lawn that has the side effect that if you go for the naturalist way of up translating to a lawn, there will be a zillion tracks. and it'll probably ruin their viewer because you'll get very sparse data on each track. it'll be like the old referring expression generals visualization in the map task. you know, when they talk about one object, one landmark and then another one that was brilliant. well, it's big, right? yeah, it is big and you do have to scroll through it to see what's going on, but because you very clear picture what's going on. well, we'll see if a lawn likes it or not. yeah, well, okay, so we better do a test one and we better also like have in the representational list of parts, like even in the nxt of translational list of parts. yeah, it affects the way we do the nxt. yeah, but there's only list parts in the gdf. so, yeah, that's not a problem. there's a base basically, well, there's three places where you've got the id there. so you've got an id for a part. you can id for a location on the screen, such as the target config, the clock, whatever else. and then we can easily add ids for the two most points and the two gazes. and from that, and basically all the tracks are doing is saying, at this, between this time, there's a look at this object. yeah, this id. so, let's say it's effectively a track for each id. okay, so what about the point where a part becomes the construct? you still identify it as part. yeah, but what should lose that? well, what happens there is that the two, the existing parts basically cease to exist. right. and a new part with a new id starts existing at the point where they're joining. so every time a part is added to the construct, it becomes a new part. so the construct actually has, say, it has six things that are added to some initial thing. okay, so if there's just the initial thing you put in the middle of the screen, that's just the initial object. yeah. as soon as you put a part, there's construct. but it's construct one, because when you add another part, construct one ceases to exist. and you get construct two. yeah. right. so actually defining all of those as the construct is going to be the trickiest thing. it's also going to be a problem, because you're going to have one part to construct forming in the middle of a fixation. right. so it's not going to be quite as clear. right. so you're looking at trying the one, right? and then it becomes a success. and it becomes constructors, simply whatever. and there could be more than one construct at a time, right? there is no thought construct. and then you can start again. you can build sub sub-samely with that. you can link the stuff in. but why does it, why does construct one become construct two when you add something to it? because the... yeah, that's what's always working the moment, because it's generating any id when you try to new part. oh, and this is because we don't want it to stay triangle one. when you start with a construct, it's not a construct at all. it's just a one thing. and we don't want to triangle one to suddenly have. yeah. well, the problem is that all of these things are popping out of existence. so do we know the difference between... we broke it and it went away. and it's now part of the construct. yeah, there's joint events. so if a joint event... if there's joint event linked to the item, then you know, it's become part of a construct. or... can we tag the constructs with what's in them? yeah, the constructs were already tagged with it. so there's actually a subpar of the data format, which says, freeze construct, which two parts made that... okay. so we could essentially... well, then we could cumulative... or it is a new construct, because it has a new list of parts. yeah, but you can still track what parts went into it. right. so you can still find triangle one, whatever. some fancy programming is going to have to be done to say, i was looking at triangle one and i'm looking at triangle one in construct one. yeah. because the first construct was triangle one in square one. yeah, but that's easy to me, because the... each construct has the ideas for the things that construct it. so now we have to ask whether... so let's imagine this. we've made a construct of two parts. and we're triangle in a square. and we're considering now adding something on to the side of the square that isn't attached to the triangle. okay. are we looking at the square? are we looking at the construct? yeah, that was the next question i had. yeah. you'll be looking at construct, because that's not it. in this definition, you'll be looking at the construct. yeah. there isn't a way to figure out that you're looking at the square rather than the triangle. well, we'll be looking at... yeah, we'll be looking at... the last thing is that we have the echo... the echo traces from the ascii format. so if you want to be able to say i'm looking at the square instead of i'm looking at the construct, it's possible to get that data out. it is. yeah, it's not doing it in the draft challenge at the moment, but i can easily add it to give that information if you want. okay, because that's the example... presumably that's the best example of overlapping areas. because if the thing... the two things are now about it. of course there's an area which is kind of a compromise to them. okay. so what i'm trying to run through in my head is that we can always tell the difference between something going out of existence, because it's joined a construct, something going out of existence, because we threw it away. suppose we pick up... we screwed up the first time we put the triangle with the square, and we threw it away. we decided we didn't like it. and we took another one. is it triangle one? is it triangle one prime or something like that? it's the replacement for triangle one. yeah, if you create a new part, it gets a new id. so if you drag a new part out, it's a bit... well, do i know what it replaces? you don't, because you'd have to have human coding to do that. you'd have multiple triangles that you broke and you want to know which one they're planning on using it for. this is true, but if i have triangles one, two, three, right, and i throw them away, any triangles i take out are two, place one, two, three. well, you know which mold they come from. and so, you know which shape they match, but you can't possibly know which one of the ones they're meant to replace. yeah, i mean, you don't... you don't know which one they're meant to replace, but you know they're not meant to replace. you can either have them thrown away. they can't replace... the new parts only appear when the previous one's broken. right, so the new parts are replacing those which have disappeared from the screen. and if there's no one tr1 track, the tr1 track is gone. oh, so there's no two parts with the same shape? oh, there are many. we're same shape, but not the same shape in color. same identity. oh, the same shape in color. right, okay. oh, is that true? you've decided not to make all the triangles really square. that's what they're at the moment. okay, so you can't tell what is meant to replace them, because it's the same... it's just in case of the mold, right? yes, that's the way it works at the moment. i assume that's how 9mg had set it up. okay, so... that's back to... so there... tim's... yep. so shape plus color. they are individual... they're unique. yeah, all the parts are unique. so we're hang on, that makes the task a little bit easier. yes. right? 10g, a much easier one, you can see... all the lines. so... it is just a construction task rather than a puzzle. indeed. which kind of leaves you with an obvious way of making the same task harder. and easier, doesn't it? yeah. but... this also... that's hard to code. i mean, that's really a thing we might do. okay, so now let's make sure that the coding would survive that. it's just... it's a beautifully controlled situation. the construction task is essentially the same. it's the figuring out stuff that gets harder if everything is purple. for just to choose a color at random here. yes, i think the ending is probably the same. the two triangles, isn't there? there's two identical triangles in the tangram. yes. at the moment, there are two small ones and two large triangles. they're actually the same physical size and shape. at the moment, they're in different colors. that also means in the new parts list, they're there for, you know, two large triangles and two small ones. whereas in the revised edition, if they were all just black, they'd only be one more in the new parts. when you specify these things, do you specify the molds? or does it figure out what the molds are based on? so is this hard-wired-in-the-tims programmer? is it just an artifact of the way we... it's hard-wired. yeah, yeah. when you specify the molds in the... in the file that generates the parts, we've got list of parts. the molds are based just taken out of the file that generates the first-first parts. right, okay. so, so, how many parts... how many parts are in the file? how many parts are in the file? that's how many parts are purely in the parts box. but if you have five black triangles, they're going to be five black triangles in the parts box or one. if you have five black triangles, they're going to be five parts in the five black triangles than the parts box. so line the words that you need for. in the initial configuration, you can reuse a triangle. so if you only want one black triangle, you used create one black triangle in the parts box and then reuse that black triangle five times in the configuration. mm-hmm. as long as this is possible. so i mean, that just is a kind of thing, which is so simple, so much like a single. yep, same. one zero variable change that it did. but what would the written code be? because i'm trying to map this onto baufix. and baufix has multiple, you know, all the nuts are red or all the flat things. what colors can have different nuts? well, the same part, the same part is different colors. oh yeah, yeah, but they don't have enough to make unique. no, i mean, there's more than the multiple pieces are the same. so why when you say a red nut or a green bolt or a long green bolt, then there'll be lots of them lying around. i think that's how the robot is set up too. five green bolts. here is one. i think we've got to the point where, you know, to try to summarize, we think tim's program can do both of these conditions that you want. but i'm still worried about what the effects are for analysis because you were aiming at something in the gdf format. and i wasn't quite sure what. so all i'm doing is kind of worrying out loud about all the things that will happen that will miss by a simple view of, for example, regions and looking at triangle one. yeah. when it's triangle one, not triangle one anymore. so, okay, so i'll summarize what we said about that part. every time you cast off a new part from a mold or, you know, every black triangle has a different idea. and you know it's a black triangle because you know which mold it came from. yeah. but you don't know which part it was intended to replace on the screen because you can't mind read. it's true. so how can we define the shapes that people build? what do you mean define? well, if, assuming i was, for a moment, i was jp and i wanted to know how they actually went about building a thing. okay. and i wanted to look at the strategy. and i wanted to see if the strategy was different when we could talk about it. and when we just picked up whatever, i mean, i suppose i can't talk to you and i'm doing this task with you and i can't talk to you. the thing which is going to be hardest for me is making elaborate plans with you. i can reach for the next thing and you can go where i reach. but if i have some, you know, subgoal, some long term subgoal of doing something clever with putting these together because it's hard and putting these together because it's hard, it's going to be almost impossible to convey that to you. and the difference in the history of construction is an important thing and i wonder how we can get that information back. i think that this is a human coding that is part of the action coding because i don't see how anybody but a person watching this can guess why they cast off this thing at this time. why is not, that's not the question i'm asking, the question i'm asking is what's the history of the construct? so you have the names of the things in there and you have two constructs, suppose we have two sub constructs and whichever one had two pieces put together first is the earlier number of those constructs. how do you tell the difference between adding a piece to this first construct and creating a second construct? when the final construct, the way the constructs are defined in the file, you've got your parent construct and the parts that are constructed out of. it's parent child relationship. the child can be a part or it can be none of the construct. so construct two, construct one is red triangle and green square, construct two is two green squares. construct three is a red triangle, a green square and another red triangle. i have looked at the construct four but that's okay because they all have different underlying part numbers. and when you say what a construct in, so how are we going to tell when, for example, you think we're going to have to do human coding and when two sub constructs are put together. no, that's a definition where the construct has constructs as children. yeah, the join action, the result, what you need to a construction part, two parts and whatever you take together. construct. you've got time when that happens. you can see that construct appeared at that time. and you can still track the children of that construct. so we can zip through this and look at all the all the interactions in which people built subcontract constructs first which we expect them to do as a wild hypothesis more when they have verbal communication than when they don't. okay, and we can do that by simply searching for any constructs that have constructs as children. yeah, so we can easily look at things like that automatically. it's just the why they get new parts that's the problem for us. we can't, if they suddenly, if they decide to get a part of a mold, we don't know, we can't know why until they do something with it. if they, we haven't actually made a rule that you can't collect extra parts, right? extra parts don't appear, so you can't collect them. oh yeah, you said that. yeah, there are, there are, it's like grayed out there. yeah, but you can see the mold is there, but they don't come filled. no, no, i mean, you have to break one to get one. yes, okay, you can, but you can break one. when you break one, you don't cast off the mold yourself. it happens automatically. yes. oh, okay. never mind that. it appears and then you like it. so they just have to use it. yeah, the new part lights up sort of thing. oh, but they have to drag it. i'll pass the mold one. yes, you have to bring it to play. and you can't just bring extras in case you know screw up. you have to screw up first and then you can bring it. yeah, that is one thing unlike the, see the bow fix or anything. yeah, there aren't any extra parts and at the moment the software doesn't. but it does have replacement. yes, replacement, but no superfluous. so you can have a standard stock of extra parts that will never use it. okay, so this why question doesn't even arise. so you appreciate, you appreciate the cost. because you know what they're going to do with it when they decide to move it past the mold line, they're doing something with it probably. and you'll know what they're going to do with it because. yeah, but by the time both of them are doing that, they must have already broken something. so you'll love what they're replacing. okay, is there a way of telling the difference between intentional and intentional breakages? how would you do that? intentional hole. in the sense that they break deliberately when they bring them into the new parts. yeah, it's like the trash can idea. they both put their hands on a construct because they don't like it. yeah, but there'd be no way of cutting that automatically. right, how could you possibly do that? you have to hope that there's language in one of them say something. but that's a human coding, right? so that just doesn't be coded. there's no way you could tell that just when they're. the role movement or something. so not generically. because if they're going to do it by gesture, they'll build up a convention. so that's going to be a particular problem for jp, right? remember all the things we're looking at are with language and without language. and it's going to be very difficult to tell whether they broke something intentionally without the language. which means that they develop a convention. suppose they start off with language and then they say. yeah, okay. but this is probably part of the action coding. sure. so we just just want to make sure that we make a wish list. right. wish list. as a side effect. i'm trying to remember if the people deliberately break things by moving two pieces together. they don't break. they do. if one person's dragging a part to a part that isn't that part that's just sitting on the screen. there's not being touched. they both break. so the intentional thing is when they actually both click on the same object. and it breaks. for sure, you know, that's or well, it's not necessarily intentional. they could just screw up. yeah, but they could discuss to set it a break something. yeah, i don't think that's very good. no, we'll never get away with that. we'll get a bad score. let's just throw that away and start again. yeah. wish we had fixed score problem. have we? oh, yeah, yeah, it was through the rotation. oh, yeah, percentage score. yeah, so rather than the number of panel please or some like, no, the score. it was the percentage overlap and that made the score. that's that's a week's work. the problem was to do with the. no, which which they had real to and absolute peace and it's all to symmetry. but that's not the fight. it wasn't it wasn't a bug. it was a don't tell me it was a feature. no, it's them just forgetting to find something that had to be. and the dutch lock. yeah, yeah, which is probably a documentation fault. it's in the documentation. but it's like, it's quite a long page. yeah, of course, it's quite media problem. not prominently flagged. yeah, exactly. a communication flaw. okay, so we can that's now just lovely. is there any crazy? well, one last thing. is there anything else you want to tell us about the prior part of this, which is the, you know, what else is holding you up from? oh, well, yeah, we should go back to the beginning. the camtasia was tested last week and initially we were a bit worried because in the old version, it seemed to interfere with it. uh-huh. but when you when craig reconpiled it into this new version, it seems to work fine. yeah, right. so it doesn't slow down the eye tracker. doesn't do anything nasty. so we can tell. so we pay for it. there's very small graphical bugs, but it's not it's not a big thing. it's like color white pixels in the course of it in the course of a cause of a task. so it's it's nothing to distract. nothing important. nothing big enough. they're going to look at it. right? no. all right. so the last, i think i'm sorry, you know, i had a sort of emails from you and i probably didn't catch everything. the problem was that there are two temptation records. yes, they will now have to be two camtasia records because each person actually sees a different screen because of the gaze. they don't see their own gaze. they see the other gaze. yeah, the other gaze. so they'll need to be two safer camtasia videos. yeah, yeah. oh, do you need two copies of camtasia, do you? hopefully. officially or the question is the release of camtasia where you just need one editing thing and two recording things because the recording, the recording program is just quite a small program that just generates the video. so i don't know if it's having a look at the licensing for that just to see. so you're going to look into this, right? yeah, i hadn't thought about how to assume we just get one and one license could run a lot both of us was technically she had two. well, look at the license conditions. it might not. i suspect that it will be per machine, i think. i never prejudiced licenses in club rhythm. okay. i'll have a look at the actual camtasia license. the other thing we... well, and hold on before we get going further. so this has implications for data storage, right? because we've got... well, no, this is three times, right? because we've got... oh, no, we're going to build... we're going to use joe's script to build the videos on the flight, right? because it's fast. so the permanent storage is just the camtasia stuff. so... is that a problem? where are we putting things? is there such a thing as a dual track video? because you can certainly mix things. what ideally one wants, one doesn't really want to have these things. because we're using them for backup and for coding. we don't really want to play them. we can play them, in fact. and, in fact, we'd almost always want to use them in exactly in parallel time-aligned. you can dump them into one video frame if you don't mind losing resolution. but that's maybe a problem right. well, the other problem is camtasia has to be manually launched and both machines separate. so the synchronization is going to be a problem? yeah. what are we doing for synchronization otherwise? during the task, there's a flash in a bleep. oh, i mean, not during the task. before... before we... yeah, but you're not asking, yes. okay, so that we'd have to realign them. we couldn't yes. dump them from their start points. well, maybe you could. the thing that you're dumping them onto just starts running with flash in the bleep. you turn on the two copies whenever at different times. but there's still... no? is the... what are they? i don't really understand the parts that are operating here. camtasia's are turning on. there is no timestamp that comes from some common source. no. they're on two separate machines and you start and end them separately. they're not talking to each other. they're just recording. you start it recording. it starts recording what's in one screen. and you start the other recording on the other machine. so... and they're... they're totally simply doing all the other ones. these are backups, right? so the flash... so the flash... it allows you to hand synchronize them later if you need to by stripping extra video off the front. as long as you make sure you start them before the flash, then you're fine. but there's a cost of having to go to backup, which is synchronizing them. so they'll include things like the itracer calibration. yes. which is not a bad thing actually. because sometimes you want to go back and find out if this was just a particularly duff subject. oh, yeah. see how long it took them actually. that's true. how long did it take them to calibrate? yeah. every time we calibrate it, how many things... things before the validation worked or something. oh, okay. so you should start the camtasia really early, right? well, yeah. at the moment that's why i was assuming... right. okay. no, that actually saves you hours trying to make somebody's data smooth out when it won't. because... go back and actually, yes, they were crap. that's a technical term. technical categorization and psychological research. um, yes. the other thing we're getting sort of date was the microphones. because only one of the camtasia videos will actually have the same track. and that's because... uh, we're just getting... we've got one cable and two mics. it's supposed to be. well, we need sound recording. right? that's... that's two track. that's... yes, so at the moment, it's in... what we've finally... just at 12 o'clock today, looks like we've got it sussed. is to get... one channel... one microphone for me in the left channel and one being the right channel to merge into a stereo... uh-huh. so, a whole file. uh, unfortunately... on what? sorry. on one... machine. on one of the... the display pc. the camtasia video. it's... no, or... move the... multimedia... that's not what you're putting it. i mean, that's our only sound record. yes. well, okay, you've got the proper sound record, but you're not dumping it... through camtasia to record it, right? you... yeah. it's camtasia that's recording. what... before we were going to use camtasia at all, what... what were we going to do... what were we going to do with the sound? uh-huh. yeah. so, uh, uh... is there any sound degradation that comes about from putting this through camtasia, rather than running it at straight? no, you got... yeah, you go exactly the same access to sound quality as you got from anything else on the windows. so you can... you can decide whatever quality you want. so... okay, so what you're planning on doing is bunging it on one of the camtasia tracks, and then splicing it off the camtasia track. it's an easy bit of... yeah. and then you're going to bung it on the other camtasia track too if you need it, right? but we'll just... we're going to store all three separately. then... and the sound is going to start at the same time as one of... that arbitrary one of the camtasia videos. but you'll know when the real experiment... you'll know the relationship between that and the itracker timings. uh, yeah, because the... the... uh, yeah, because the synchronization, the audio and visual synchronization comes at a specific point in the itracker file. yeah, no human intervention required. it's timestamped. no, it's... it's stamped into it. so it's just after it prints the line starting experiment. yeah, i'm pretty sure it's... yeah. but hold on, do we need that? i mean, i thought the way that tim had this set up originally... the audio... the timestamps used... there would be joint timestamps between the audio and the itracker. so that, you know, the audio record... 10 seconds in was the same as 10 seconds in the itracker record. so that we didn't have to do any extra hand work, you know, any chopping the starts of audio signals to get. there was nothing... okay. so we're relying on your matlab script to get us the chopped version of the audio, right? uh, well, the matlab script, uh, based just says... yeah, it gives you the time of the audio beep in this end signal. right, so we can either adjust the itracker track data or we can actually chop the audio signal. yeah. take off the first, whatever, 70 seconds. there's going to be a way to sooner or later to align the itracker, camtasia 1, camtasia 2 with two sound channels. yeah. yeah, but uh, but um, lining up the camtasia 2 is going to take... we... he's working on a matlab script for the sound, but not for... so the one that's got the sound on it, that'll also tell you where to chop the video to get it to line up. the one that doesn't have the sound on it, it won't. oh, the beep will find... oh, so it's just the bleeps. oh, okay, so... no way. no hand for synchronization required at all. as long as the scripts work. right? yeah. that'll be basically the only thing that's going to be... ...that's going to be the same thing. okay, how confident are you about the... ...finding the script? yeah. okay, how confident are you about the... ...finding the script? yeah, that's the same thing. yeah, that's the same thing. okay, how confident are you about the... ...finding these things? break off the... you've seen them, it was... yeah. so we just have to... ...hope we don't have any subjects with odd vocalizations. yeah, i don't see them with 10 hickaverts, but you know... they also tend to have a funny... ...funny shape. beeps, so... yeah. okay. yeah, because this is the dropout test. yep. okay. is there an in signal? when you decide it's all over, does it... yeah, the signal at the start and the end of every trial. right. okay. so when you've... ...prest were finished. yeah. ...pings back at you. yeah. okay. it's just that all kinds of crazy things happen when you're... ...saving a percentage of a trial. sometimes a good, you know, being able to do that is sometimes a good idea. okay. oh, yeah. yes, it's a stereo jack. it's a stereo jack, but it's a mono... ...microphone. you got a solution for that then? lining. let's go through a line. so it's quieter because it's not... ...so it's not powered, but it's still... ...yeah, we still pick up the signal. you should... there's not a better solution that involves... yeah, i think we do something better than that. because, you know, people might want to use this first. be sure to recognize something. you never know. the date is there. yeah, i mean, it's crazy ruin and anticoach. which we specially build in anticoach. yeah, it's on dead in the room, which we specially build for this. and you're going to want for a line. we shouldn't screw it up more than we have to. is there anything we can do to improve this? oh, no. well, no, no. better to collect it sort of... ...with the powered microphone or something. well, when they're out there, they have batteries in them. but it's not... there's a... ...the thundering pad because of the lining out inputs. so, i thought a bit of solution was fixing this problem with the mono microphone. socket. sound card? so, you said the problem was the... the sound of the sound... the sound of the sound of the stereo, the input is mono. right? the jack that is plugged into is stereo. but when it's recording for microphone, it records in mono. so, is that fixable? like, is there any way we're in the sound third? yeah, and these are good. i think the new sound card sounds a better solution than munching about with trying to filter white noise out. oh, i think we'll remember the old sound from the... well, the old sound from the 10th of... well, i suppose one thing you do is record the speech, single-separate for each person, but then you have to pull the two sounds together. which isn't hard. but if each machine recorded, we could record it like the... so, i think you have to align the videos anyway. right? yeah. yeah. put two on us and do a stereo signal. yeah, see easy. i'm not a technical person. if not, if not, if not, if not, if not, if you're not, if you're doing a matlab script, you just read file one, read file t. and then... so, is there any reason why we don't do that? yeah, but then the matlab script will tell you how far apart there. because you can just measure the drift between the two of them. so, you get a list of where the beeps are. and then you say, right, this stream is like i don't know, 0.25 seconds behind the other one. says robin thinking about cutting and splicing. yeah. yeah. well, it's... in the old days, we probably would have... if they'd been in the same room, we would have read a little stereo thing. my background is back up as well, just to make sure. because it's slightly dicey, you know, if his scripts don't work, then don't get the old one. i want to see one of them look really nice before we start running the subject. do you want to do that? it doesn't have to be a real trial. it just has to be two guys talking in the two bits. and then i just want to know it works the way you expect it to work. this is not a gesture of mistrust. this is just experience that if anything can screw up, it will. we've both been so badly picked in the past. i'm trying to choose my language carefully because we've been recorded. you hear more choice language at the point when we've all been a lot of work. then we discover we can't use the session because of something we didn't think about. yeah. but this sounds reasonable to me. so i think... do you know if they're body-sector things? mm-hmm. do they both have the same sound card problem? i wouldn't count on it. do they both have the same sound card problem? i wouldn't count on it. they both got the same sound card. okay. so... yeah. it's probably worth mentioning this to the guys in the garage in toronto, right? to save. yes. yeah. so the external version has plugged that size. uh-huh. and that is stereo microphones. right. yeah. the other one's like the smaller size and that isn't stereo. so the card can do it. it's just that the connectors on the connectors are the back of the computer. come. well, yeah. i think tell the guys... i think that's a... if the documentation said it could record in stereo, then i think we should talk to them about how they've done this. you're not sure from the documentation what it says it can do? the bottom trouble is finding it. the question is, is it as much of what the size... yeah, yeah. yeah. but as far as we can tell, when you find the website of the cravalize website and the review of it, um, and they weren't entirely clear, but they both suggested that it was a monomacrophone. yeah. i think it's not the people i think you can put it into the other... yeah, it's just the way they're wired it. so it's getting late and i've got a two o'clock and i've got a nice lunch. so i want to eat my lunch today. what did you want to get through today more? i think i was useful going through your expectations about this because that's quite a bit clearer in my head, at least. yeah, but i think mostly we leave you to go away and redesign the gdf and add new bits to the gdf along these lines. yeah, so basically the output gdf is just going to be a whole series of events. yeah, we're starting in time and the event's going to have whatever the object is that's been looked at and things. and then, yeah, and then it's a matter of we can put whatever filters we need after that so you can say, right? i just want, so you can say, from the time where they picked up triangle one to the part time it became part of the assembly, find out how much how percentage of time they were looking at it or whatever. okay, so given that there are these events recorded, we can use any of them as the beginning of any of them as a start point, for example. there are also motions being recorded of objects. yeah, so you've got movements, there's look events, there's fixations of blinks in there at the moment as well. and yeah, and oh yeah, and say, yeah, look, say, look, say objects, look, whatever else. but i think the thing to do is have a few to grow away and think about it this way with different tracks, with different objects and the, there are kinds of things we've added about whether they're looking at the other person's gaze and what have you. and try to change the specs so it reflects this and maybe, maybe by that point there will be some sample data or something. and the right thing to do is first to look at the spec the way you understand it now and some data. and then alan will have new ideas about what's needed or about these post-analyses, you know, and then we can add them in. but it's going to emerge over time, that's clear. that's great. i before we break up for lunch, i just want to make sure that i know how long it's going to be before we run mode. okay, so the sound thing is, it stands in our way, we need to be recording sound online. okay, so that's the thing that has to be solved. the shape thing is solved. yeah, that's that's solved now. we think, yeah, test, we believe. we have to test, so that's that should be done this week. in fact, like tomorrow, for example, all the shape problems are solved, generating shapes, no problem. scoring, shape overlap, no problem. nothing is a problem. there are no visual displays. you don't have your models. yeah, they had their inspection last week, jp staggered away from it. so, the moment you understand what you think is going to be like that. so, the moment you think that you're going to be like that. yeah. because i know you're going to trigger it. yeah. well, anything you actually need fixed. you know, in that case, joe doesn't live here anymore, right? well, but he wasn't going to be booking any time to us after the 31st of october. so, that means that any bugs that need fixed in our corrects responsibility, right? you don't know how many change on that, right? that's what he said to us. i need to discuss with him. i would assume, you know, no more contact with joe. it's not fair to get work out of somebody for free. so, you know, ask craig instead. well, he's physically here. we want to pay him for some more time. you can do that. would that be a just better use of our time and get? yeah. well, he wasn't paid in advance. he's being paid in a rear. so it doesn't matter. i think he is around and i believe. and if i think it's better to have all the software, i mean, it's not big things. it's just maintenance of this program at this point. but if everybody has a lot to do and, you know, joe could give it a couple of hours, which is what it might take just to fix it, then let's do it because starting run time is not going to be. yeah, if you can give it, you know, like, because the problem is you've got to have it immediately when you discover bugging that. and we can make craig shift all his other priorities to do this because we bought him. right. but we can't. we can't make joe do this. yeah. so it's kind of between availability and speed from start to finish, given that this is somebody else's code. but it sounds like you don't think there's anything that actually needs fixed at the moment. because we only need this to work well enough that you can use it for something. right. we got what we're building models. right. how many models do you need to completion and how long does that take? and you got. well, and you know about complexity. you're waiting on malice. you can. cold call her today is after me. yeah. i think so. i have to check back with. with jp fairly soon. ok, he wanted to. the next 18 month plan. great. deliverables. great progress with the experiment. well, that's what we're doing now. ok, so what do we think if you have a fairly hectic week? are we looking for subjects next week? i think. ok. adds go up. yeah, i do. i do. but i think ad should probably go up this week. we want people for next week. is that ok? is anybody now terrified at the thought that we're live next week? there are people coming in here. one after another or two after two. more likely. ok, is this generalized generalized anxiety robin or do you have a specific thing that. ok, so aside from the usual angst which we all suffer when we go live, so we want to do some piloting at the end of the week. yep, yeah, so we'll get we'll get the audio stuff tested for single mic friends. yeah, get that test in a little basement. i assume that's something you need me for in terms of that. right. oh, yeah. but she's actually relaxed that somewhat. ok. yeah. ostensibly book time which isn't. so you can dash in there for half an hour at a time. does it sound very useful for you? ok, well, ok, we have a solid booking for all the mornings anyway. right. and except by permission of us. all right, we own it. so we can change that and everybody acknowledged the other week that we that we have. but it would be kind to tell her ahead of time which of your one accession is your ball. yeah, yeah, yeah, yeah, yeah. don't worry. there's a booking system. right. so it's public. what's booked in one of these? i thought that was the problem that your mornings weren't sliced off on a booking system. maybe you should get on the book mornings as far as the i can see. does you know if you're sat told use the booking system? well, we think we spoke to all the people who use those facilities the other day, but we could be wrong. yeah. and one of the people upstairs downstairs have, you know, as rules about who you hand the keys to. well, because you know, we like people to know to ground the. oh, i thought the lending for the book system. caroline. from caroline or the general office. see, because you're supposed to have training in, but no, they need they need an account on this machine to actually use it. they need account on the machine. so that's the thing that they could book. they couldn't actually and you control those accounts. okay. that's fair enough. okay. okay. we're also working on a way of making sure that the machine's returned to zero state when they're. uh-huh. yeah. and you come off. that's a because it's because then they love the first time. well, people have been leaving various bits of who knows what around them. right. which we think is what's critical. yeah, yeah. okay. i really have to get out of here. so, um, what, what else is important before you run? nothing. all right. piloting, piloting, piloting. you have, we have to build up the things we have to try the machine. things we have to check them with marlos and jp that they like the representation of the variables. right. how about, you have any time on friday? oh, i don't think i brought my diary up. uh, but maybe why? maybe why? you know, back. maybe you and i should be the pilot subjects. first pilot subjects, the ones who know which questions we want to ask. and then we should get another pair who are naive to the whole thing. okay. so. yeah. this is generalized floating anxiety. no, no, it's it's it's it's a wisdom, but yeah. well, um, because actually we can, you know, we make comments. they feedback and a vote into the development. hmm. so do you know what time of day you might want? because i should, i should check that. okay. you don't, you don't mean me involved in the pilot, do you? well, you all have to, unless, unless the bug report, yeah. you'll have to be there too. oh, yeah, i'll be around, but yeah, i want you to. hopefully it all runs within, yeah. i can relax. okay. so that all sounds good fun. well, i can just leave you guys here, you know. hm, why not. be, oh now because that's the... yeah, but we'll tell you later. yeah, we'll tell you later. what are all of the things? why do you know that there is no such thing? and then you know, so, hey, look, i'm dr. andrews. i'm the journalist in the industry. i think that's the offensive of the job services. but this is the job service. there is no job service. i'm not sure if they protected you. or james. he has a tag that he loves you. i've heard he has a tag that says, but i'm looking forward to it. and he's going to be the biggest tag. and bob logan's... i'm not going to be the biggest tag. i'm not going to be the biggest tag. i'm not going to be the biggest tag. yeah, i'm going to talk to him. i'm going to say that he's the biggest tag. you think? there's something wrong with him. i'm going to say that he's the biggest tag. he's the biggest tag. i'm going to say that he's the biggest tag.
